{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ebb700",
   "metadata": {},
   "source": [
    "Every algorithm involved in scikit learn via an 'Estimator'\n",
    "First Import the model general form is given below\n",
    "\n",
    "from sklearn.family import model\n",
    "\n",
    "for example:\n",
    "    \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d218e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7130b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a5d054",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LinearRegression.__init__() got an unexpected keyword argument 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: LinearRegression.__init__() got an unexpected keyword argument 'normalize'"
     ]
    }
   ],
   "source": [
    "LinearRegression(copy_X = True, fit_intercept=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cbf6d",
   "metadata": {},
   "source": [
    "# program for Training and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc510c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601192cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting or creating the datas\n",
    "X, y = np.arange(10).reshape((5, 2)),range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babca5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620a3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f06ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the datas into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6cc7b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676d1623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbedd40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 9],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "173bafc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6b1f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can train or fit the split data\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6e8a6",
   "metadata": {},
   "source": [
    " Model has fit and trained on training data\n",
    "model is ready to predict labels or values on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a9049df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 3.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we get predicted values by using the predict method\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d07d8",
   "metadata": {},
   "source": [
    "# Loading a data with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbf9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8b8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going to use popular pre loaded datasets to use\n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "features = digits.data\n",
    "target = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ea5ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce4e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcdd2f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccede4",
   "metadata": {},
   "source": [
    "# Creating a simultated dataset\n",
    " or how to create a own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55a1265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27abd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, coefficients = make_regression(\n",
    "    n_samples=100,\n",
    "    n_features=3,\n",
    "    n_informative=3,\n",
    "    n_targets=1,\n",
    "    bias=0.0,\n",
    "    effective_rank=None,\n",
    "    tail_strength=0.5,\n",
    "    noise=0.0,\n",
    "    shuffle=True,\n",
    "    coef=True,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9f831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ 1.29322588 -0.61736206 -0.11044703]\n",
      " [-2.793085    0.36633201  1.93752881]\n",
      " [ 0.80186103 -0.18656977  0.0465673 ]]\n",
      "Target Vector\n",
      " [-10.37865986  25.5124503   19.67705609]\n"
     ]
    }
   ],
   "source": [
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are interested in creating a simulted dataset for classification, we can use make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a628597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the library\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92198059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ 1.06354768 -1.42632219  1.02163151]\n",
      " [ 0.23156977  1.49535261  0.33251578]\n",
      " [ 0.15972951  0.83533515 -0.40869554]]\n",
      "Target Vector\n",
      " [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# generate features matrix and target vector\n",
    "\n",
    "features, target = make_classification(n_samples = 100,\n",
    "n_features = 3,\n",
    "n_informative = 3,\n",
    "n_redundant = 0,\n",
    "n_classes = 2,\n",
    "weights = [.25, .75],\n",
    "random_state = 1)\n",
    "# View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658975b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally , if we want a dataset designed to work well clusttering techniques, scikitlearn offers make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4908ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the library\n",
    "\n",
    "from sklearn.datasets import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef5da050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ -1.22685609   3.25572052]\n",
      " [ -9.57463218  -4.38310652]\n",
      " [-10.71976941  -4.20558148]]\n",
      "Target Vector\n",
      " [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate feature matrix and target matrix\n",
    "\n",
    "features, target = make_blobs(n_samples = 100,\n",
    "n_features = 2,\n",
    "centers = 3,\n",
    "cluster_std = 0.5,\n",
    "shuffle = True,\n",
    "random_state = 1)\n",
    "\n",
    "# View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b98c3",
   "metadata": {},
   "source": [
    "# Data Wrangling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the library \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create url\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
    "\n",
    "# load data as dataframe\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# to get the first 5 rows\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2c3ba",
   "metadata": {},
   "source": [
    "# Creating a Data Frame\n",
    "pandas has many methods of creating a new DataFrame object. One easy method is to create an empty data frame using DataFrame and then define each column separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f533a584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame()\n",
    "# Add columns\n",
    "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
    "dataframe['Age'] = [38, 25]\n",
    "dataframe['Driver'] = [True, False]\n",
    "# Show DataFrame\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd276d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamilarasu16\\AppData\\Local\\Temp\\ipykernel_11796\\2307538769.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dataframe.append(new_person, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molly Mooney</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False\n",
       "2      Molly Mooney   40    True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, once we created a Datframe object, we can append new rows to the bottom\n",
    "\n",
    "# create row\n",
    "new_person = pd.Series(['Molly Mooney', 40, True], index = ['Name', 'Age', 'Driver'])\n",
    "\n",
    "# Append row\n",
    "dataframe.append(new_person, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f1ebf",
   "metadata": {},
   "source": [
    "# Describing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82d9c55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create url\n",
    "\n",
    "dataframe = pd.read_csv('https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv')\n",
    "\n",
    "# to get the first 2 rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4a5e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the shapes of the dataset\n",
    "\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1810663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>756.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.397989</td>\n",
       "      <td>0.342727</td>\n",
       "      <td>0.351866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.259049</td>\n",
       "      <td>0.474802</td>\n",
       "      <td>0.477734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Survived      SexCode\n",
       "count  756.000000  1313.000000  1313.000000\n",
       "mean    30.397989     0.342727     0.351866\n",
       "std     14.259049     0.474802     0.477734\n",
       "min      0.170000     0.000000     0.000000\n",
       "25%     21.000000     0.000000     0.000000\n",
       "50%     28.000000     0.000000     0.000000\n",
       "75%     39.000000     1.000000     1.000000\n",
       "max     71.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the descriptive statistics for any numeric columns using describe\n",
    "\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968af80",
   "metadata": {},
   "source": [
    "# Navigating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "629fa722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                 29.0\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb3688f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass   Age     Sex  \\\n",
       "1                    Allison, Miss Helen Loraine    1st   2.0  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.0    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female   \n",
       "\n",
       "   Survived  SexCode  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get 1 to 3 rd row\n",
    "\n",
    "dataframe.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc29fd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass   Age     Sex  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  29.0  female   \n",
       "1                    Allison, Miss Helen Loraine    1st   2.0  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.0    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female   \n",
       "\n",
       "   Survived  SexCode  \n",
       "0         1        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get 0 to 3 rd row\n",
    "\n",
    "dataframe.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feadd2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                 29.0\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: Allen, Miss Elisabeth Walton, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index\n",
    "\n",
    "dataframe = dataframe.set_index(dataframe['Name'])\n",
    "\n",
    "# show row\n",
    "\n",
    "dataframe.loc['Allen, Miss Elisabeth Walton']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649127d8",
   "metadata": {},
   "source": [
    "# Selecting rows based on conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8de90e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allen, Miss Elisabeth Walton</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Miss Helen Loraine</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Name PClass   Age  \\\n",
       "Name                                                                      \n",
       "Allen, Miss Elisabeth Walton  Allen, Miss Elisabeth Walton    1st  29.0   \n",
       "Allison, Miss Helen Loraine    Allison, Miss Helen Loraine    1st   2.0   \n",
       "\n",
       "                                 Sex  Survived  SexCode  \n",
       "Name                                                     \n",
       "Allen, Miss Elisabeth Walton  female         1        1  \n",
       "Allison, Miss Helen Loraine   female         0        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top rows where column 'sex' is female\n",
    "\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e95774db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allen, Miss Elisabeth Walton</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Miss Helen Loraine</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrews, Miss Kornelia Theodosia</th>\n",
       "      <td>Andrews, Miss Kornelia Theodosia</td>\n",
       "      <td>1st</td>\n",
       "      <td>63.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appleton, Mrs Edward Dale (Charlotte Lamson)</th>\n",
       "      <td>Appleton, Mrs Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>1st</td>\n",
       "      <td>58.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vestrom, Miss Hulda Amanda Adolfina</th>\n",
       "      <td>Vestrom, Miss Hulda Amanda Adolfina</td>\n",
       "      <td>3rd</td>\n",
       "      <td>14.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilkes, Mrs Ellen</th>\n",
       "      <td>Wilkes, Mrs Ellen</td>\n",
       "      <td>3rd</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yasbeck, Mrs Antoni</th>\n",
       "      <td>Yasbeck, Mrs Antoni</td>\n",
       "      <td>3rd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zabour, Miss Hileni</th>\n",
       "      <td>Zabour, Miss Hileni</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zabour, Miss Tamini</th>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Name  \\\n",
       "Name                                                                                           \n",
       "Allen, Miss Elisabeth Walton                                    Allen, Miss Elisabeth Walton   \n",
       "Allison, Miss Helen Loraine                                      Allison, Miss Helen Loraine   \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)  Allison, Mrs Hudson JC (Bessie Waldo Daniels)   \n",
       "Andrews, Miss Kornelia Theodosia                            Andrews, Miss Kornelia Theodosia   \n",
       "Appleton, Mrs Edward Dale (Charlotte Lamson)    Appleton, Mrs Edward Dale (Charlotte Lamson)   \n",
       "...                                                                                      ...   \n",
       "Vestrom, Miss Hulda Amanda Adolfina                      Vestrom, Miss Hulda Amanda Adolfina   \n",
       "Wilkes, Mrs Ellen                                                          Wilkes, Mrs Ellen   \n",
       "Yasbeck, Mrs Antoni                                                      Yasbeck, Mrs Antoni   \n",
       "Zabour, Miss Hileni                                                      Zabour, Miss Hileni   \n",
       "Zabour, Miss Tamini                                                      Zabour, Miss Tamini   \n",
       "\n",
       "                                              PClass   Age     Sex  Survived  \\\n",
       "Name                                                                           \n",
       "Allen, Miss Elisabeth Walton                     1st  29.0  female         1   \n",
       "Allison, Miss Helen Loraine                      1st   2.0  female         0   \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female         0   \n",
       "Andrews, Miss Kornelia Theodosia                 1st  63.0  female         1   \n",
       "Appleton, Mrs Edward Dale (Charlotte Lamson)     1st  58.0  female         1   \n",
       "...                                              ...   ...     ...       ...   \n",
       "Vestrom, Miss Hulda Amanda Adolfina              3rd  14.0  female         0   \n",
       "Wilkes, Mrs Ellen                                3rd  45.0  female         1   \n",
       "Yasbeck, Mrs Antoni                              3rd  15.0  female         1   \n",
       "Zabour, Miss Hileni                              3rd   NaN  female         0   \n",
       "Zabour, Miss Tamini                              3rd   NaN  female         0   \n",
       "\n",
       "                                               SexCode  \n",
       "Name                                                    \n",
       "Allen, Miss Elisabeth Walton                         1  \n",
       "Allison, Miss Helen Loraine                          1  \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)        1  \n",
       "Andrews, Miss Kornelia Theodosia                     1  \n",
       "Appleton, Mrs Edward Dale (Charlotte Lamson)         1  \n",
       "...                                                ...  \n",
       "Vestrom, Miss Hulda Amanda Adolfina                  1  \n",
       "Wilkes, Mrs Ellen                                    1  \n",
       "Yasbeck, Mrs Antoni                                  1  \n",
       "Zabour, Miss Hileni                                  1  \n",
       "Zabour, Miss Tamini                                  1  \n",
       "\n",
       "[462 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['Sex'] == 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ddbe5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Allen, Miss Elisabeth Walton                                      Allen, Miss Elisabeth Walton\n",
       "Allison, Miss Helen Loraine                                        Allison, Miss Helen Loraine\n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)    Allison, Mrs Hudson JC (Bessie Waldo Daniels)\n",
       "Andrews, Miss Kornelia Theodosia                              Andrews, Miss Kornelia Theodosia\n",
       "Appleton, Mrs Edward Dale (Charlotte Lamson)      Appleton, Mrs Edward Dale (Charlotte Lamson)\n",
       "                                                                     ...                      \n",
       "Vestrom, Miss Hulda Amanda Adolfina                        Vestrom, Miss Hulda Amanda Adolfina\n",
       "Wilkes, Mrs Ellen                                                            Wilkes, Mrs Ellen\n",
       "Yasbeck, Mrs Antoni                                                        Yasbeck, Mrs Antoni\n",
       "Zabour, Miss Hileni                                                        Zabour, Miss Hileni\n",
       "Zabour, Miss Tamini                                                        Zabour, Miss Tamini\n",
       "Name: Name, Length: 462, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['Sex'] == 'female']['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ab5bd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Allen, Miss Elisabeth Walton                                      Allen, Miss Elisabeth Walton\n",
       "Allison, Miss Helen Loraine                                        Allison, Miss Helen Loraine\n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)    Allison, Mrs Hudson JC (Bessie Waldo Daniels)\n",
       "Andrews, Miss Kornelia Theodosia                              Andrews, Miss Kornelia Theodosia\n",
       "Appleton, Mrs Edward Dale (Charlotte Lamson)      Appleton, Mrs Edward Dale (Charlotte Lamson)\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['Sex'] == 'female']['Name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "784db841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Crosby, Mrs Edward Gifford (Catherine Elizabeth Halstead)</th>\n",
       "      <td>Crosby, Mrs Edward Gifford (Catherine Elizabet...</td>\n",
       "      <td>1st</td>\n",
       "      <td>69.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 Name  \\\n",
       "Name                                                                                                    \n",
       "Crosby, Mrs Edward Gifford (Catherine Elizabeth...  Crosby, Mrs Edward Gifford (Catherine Elizabet...   \n",
       "\n",
       "                                                   PClass   Age     Sex  \\\n",
       "Name                                                                      \n",
       "Crosby, Mrs Edward Gifford (Catherine Elizabeth...    1st  69.0  female   \n",
       "\n",
       "                                                    Survived  SexCode  \n",
       "Name                                                                   \n",
       "Crosby, Mrs Edward Gifford (Catherine Elizabeth...         1        1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to do multiple conditions\n",
    "\n",
    "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cbc282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>3rd</td>\n",
       "      <td>27.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>3rd</td>\n",
       "      <td>26.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Zenni, Mr Philip</td>\n",
       "      <td>3rd</td>\n",
       "      <td>22.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Lievens, Mr Rene</td>\n",
       "      <td>3rd</td>\n",
       "      <td>24.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3rd</td>\n",
       "      <td>29.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name PClass    Age     Sex  \\\n",
       "0                      Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "1                       Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2               Allison, Mr Hudson Joshua Creighton    1st  30.00    male   \n",
       "3     Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                     Allison, Master Hudson Trevor    1st   0.92    male   \n",
       "...                                             ...    ...    ...     ...   \n",
       "1308                             Zakarian, Mr Artun    3rd  27.00    male   \n",
       "1309                         Zakarian, Mr Maprieder    3rd  26.00    male   \n",
       "1310                               Zenni, Mr Philip    3rd  22.00    male   \n",
       "1311                               Lievens, Mr Rene    3rd  24.00    male   \n",
       "1312                                 Zimmerman, Leo    3rd  29.00    male   \n",
       "\n",
       "      Survived  SexCode  \n",
       "0            1        1  \n",
       "1            0        1  \n",
       "2            0        0  \n",
       "3            0        1  \n",
       "4            1        0  \n",
       "...        ...      ...  \n",
       "1308         0        0  \n",
       "1309         0        0  \n",
       "1310         0        0  \n",
       "1311         0        0  \n",
       "1312         0        0  \n",
       "\n",
       "[1313 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reset the index \n",
    "\n",
    "dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f31e4",
   "metadata": {},
   "source": [
    "# Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bae9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Allen, Miss Elisabeth Walton    woman\n",
       "Allison, Miss Helen Loraine     woman\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Sex'].replace('female','woman').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "364134e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Allen, Miss Elisabeth Walton                     woman\n",
       "Allison, Miss Helen Loraine                      woman\n",
       "Allison, Mr Hudson Joshua Creighton                man\n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)    woman\n",
       "Allison, Master Hudson Trevor                      man\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Sex'].replace(['female','male'],['woman','man']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09b21fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allen, Miss Elisabeth Walton</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Miss Helen Loraine</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Mr Hudson Joshua Creighton</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allison, Master Hudson Trevor</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Name  \\\n",
       "Name                                                                                           \n",
       "Allen, Miss Elisabeth Walton                                    Allen, Miss Elisabeth Walton   \n",
       "Allison, Miss Helen Loraine                                      Allison, Miss Helen Loraine   \n",
       "Allison, Mr Hudson Joshua Creighton                      Allison, Mr Hudson Joshua Creighton   \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)  Allison, Mrs Hudson JC (Bessie Waldo Daniels)   \n",
       "Allison, Master Hudson Trevor                                  Allison, Master Hudson Trevor   \n",
       "\n",
       "                                              PClass   Age     Sex Survived  \\\n",
       "Name                                                                          \n",
       "Allen, Miss Elisabeth Walton                     1st  29.0  female      one   \n",
       "Allison, Miss Helen Loraine                      1st   2.0  female        0   \n",
       "Allison, Mr Hudson Joshua Creighton              1st  30.0    male        0   \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female        0   \n",
       "Allison, Master Hudson Trevor                    1st  0.92    male      one   \n",
       "\n",
       "                                              SexCode  \n",
       "Name                                                   \n",
       "Allen, Miss Elisabeth Walton                      one  \n",
       "Allison, Miss Helen Loraine                       one  \n",
       "Allison, Mr Hudson Joshua Creighton                 0  \n",
       "Allison, Mrs Hudson JC (Bessie Waldo Daniels)     one  \n",
       "Allison, Master Hudson Trevor                       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace values\n",
    "\n",
    "dataframe.replace(1, 'one').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f963e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44fb15d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>First</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>First</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton  First  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine  First   2.0  female         0        1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace also accepts regular expressions\n",
    "\n",
    "# replace values\n",
    "\n",
    "dataframe.replace(r'1st', 'First', regex = True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a190bbd",
   "metadata": {},
   "source": [
    "# Renaming column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7071ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name Passenger Class    Age  \\\n",
       "0                   Allen, Miss Elisabeth Walton             1st  29.00   \n",
       "1                    Allison, Miss Helen Loraine             1st   2.00   \n",
       "2            Allison, Mr Hudson Joshua Creighton             1st  30.00   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)             1st  25.00   \n",
       "4                  Allison, Master Hudson Trevor             1st   0.92   \n",
       "\n",
       "      Sex  Survived  SexCode  \n",
       "0  female         1        1  \n",
       "1  female         0        1  \n",
       "2    male         0        0  \n",
       "3  female         0        1  \n",
       "4    male         1        0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column\n",
    "\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7b5e5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name Passenger Class    Age  \\\n",
       "0                   Allen, Miss Elisabeth Walton             1st  29.00   \n",
       "1                    Allison, Miss Helen Loraine             1st   2.00   \n",
       "2            Allison, Mr Hudson Joshua Creighton             1st  30.00   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)             1st  25.00   \n",
       "4                  Allison, Master Hudson Trevor             1st   0.92   \n",
       "\n",
       "   Gender  Survived  SexCode  \n",
       "0  female         1        1  \n",
       "1  female         0        1  \n",
       "2    male         0        0  \n",
       "3  female         0        1  \n",
       "4    male         1        0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Rename multiple columns\n",
    "    \n",
    "dataframe.rename(columns={'PClass':'Passenger Class', 'Sex':'Gender'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f5dbc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'Name': '',\n",
       "             'PClass': '',\n",
       "             'Age': '',\n",
       "             'Sex': '',\n",
       "             'Survived': '',\n",
       "             'SexCode': ''})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this helpful snippet of code creates a dictionary with the old column names as keys and empty strings as values\n",
    "\n",
    "# load library \n",
    "import collections\n",
    "\n",
    "# create dictionary\n",
    "column_names = collections.defaultdict(str)\n",
    "\n",
    "# create keys\n",
    "for name in dataframe.columns:\n",
    "    column_names[name]\n",
    "    \n",
    "# show dictonary\n",
    "column_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054f5c5",
   "metadata": {},
   "source": [
    "# finding the Minimum, Maximum, Sum, Averag and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1aa18966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum 71.0\n",
      "Minimum 0.17\n",
      "Mean 30.397989417989418\n",
      "Sum 22980.88\n",
      "Count 756\n"
     ]
    }
   ],
   "source": [
    "# calculate statistics\n",
    "\n",
    "print('Maximum', dataframe['Age'].max())\n",
    "print('Minimum', dataframe['Age'].min())\n",
    "print('Mean', dataframe['Age'].mean())\n",
    "print('Sum', dataframe['Age'].sum())\n",
    "print('Count', dataframe['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd941d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        1313\n",
       "PClass      1313\n",
       "Age          756\n",
       "Sex         1313\n",
       "Survived    1313\n",
       "SexCode     1313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show counts\n",
    "\n",
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "131962f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select unique values\n",
    "\n",
    "dataframe['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56c185dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      851\n",
       "female    462\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show counts\n",
    "\n",
    "dataframe['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8579daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3rd    711\n",
       "1st    322\n",
       "2nd    279\n",
       "*        1\n",
       "Name: PClass, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['PClass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1565d23",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0de93587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aubert, Mrs Leontine Pauline</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barkworth, Mr Algernon H</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baumann, Mr John D</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Borebank, Mr John James</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Bradley, Mr George</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Wiseman, Mr Phillippe</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>Yalsevac, Mr Ivan</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Youssef, Mr Gerios</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Zabour, Miss Hileni</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name PClass  Age     Sex  Survived  SexCode\n",
       "12    Aubert, Mrs Leontine Pauline    1st  NaN  female         1        1\n",
       "13        Barkworth, Mr Algernon H    1st  NaN    male         1        0\n",
       "14              Baumann, Mr John D    1st  NaN    male         0        0\n",
       "29         Borebank, Mr John James    1st  NaN    male         0        0\n",
       "32              Bradley, Mr George    1st  NaN    male         1        0\n",
       "...                            ...    ...  ...     ...       ...      ...\n",
       "1300         Wiseman, Mr Phillippe    3rd  NaN    male         0        0\n",
       "1302             Yalsevac, Mr Ivan    3rd  NaN    male         1        0\n",
       "1305            Youssef, Mr Gerios    3rd  NaN    male         0        0\n",
       "1306           Zabour, Miss Hileni    3rd  NaN  female         0        1\n",
       "1307           Zabour, Miss Tamini    3rd  NaN  female         0        1\n",
       "\n",
       "[557 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select missing values\n",
    "\n",
    "dataframe[dataframe['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dc522a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Attempt to replace values with NaN\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNaN\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Attempt to replace values with NaN\n",
    "\n",
    "dataframe['Sex'] = dataframe['Sex'].replace['male', np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec6ee9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to have full functionality with NaN we need to import the Numpy library first\n",
    "    \n",
    "# load library\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Replace values with NaN\n",
    "\n",
    "dataframe['Sex'] = dataframe['Sex'].replace('male',np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "379f58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Sex'] = dataframe['Sex'].replace('NaN', 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04c8bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>3rd</td>\n",
       "      <td>27.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>3rd</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Zenni, Mr Philip</td>\n",
       "      <td>3rd</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Lievens, Mr Rene</td>\n",
       "      <td>3rd</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3rd</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name PClass    Age     Sex  \\\n",
       "0                      Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "1                       Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2               Allison, Mr Hudson Joshua Creighton    1st  30.00     NaN   \n",
       "3     Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                     Allison, Master Hudson Trevor    1st   0.92     NaN   \n",
       "...                                             ...    ...    ...     ...   \n",
       "1308                             Zakarian, Mr Artun    3rd  27.00     NaN   \n",
       "1309                         Zakarian, Mr Maprieder    3rd  26.00     NaN   \n",
       "1310                               Zenni, Mr Philip    3rd  22.00     NaN   \n",
       "1311                               Lievens, Mr Rene    3rd  24.00     NaN   \n",
       "1312                                 Zimmerman, Leo    3rd  29.00     NaN   \n",
       "\n",
       "      Survived  SexCode  \n",
       "0            1        1  \n",
       "1            0        1  \n",
       "2            0        0  \n",
       "3            0        1  \n",
       "4            1        0  \n",
       "...        ...      ...  \n",
       "1308         0        0  \n",
       "1309         0        0  \n",
       "1310         0        0  \n",
       "1311         0        0  \n",
       "1312         0        0  \n",
       "\n",
       "[1313 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6134e0",
   "metadata": {},
   "source": [
    "# deleting a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best way to delete a column is to use drop with the parameter axis = 1 (i.e, the column axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d3a09a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass     Sex  Survived  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  female         1   \n",
       "1                    Allison, Miss Helen Loraine    1st  female         0   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st     NaN         0   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  female         0   \n",
       "4                  Allison, Master Hudson Trevor    1st     NaN         1   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete column\n",
    "\n",
    "dataframe.drop('Age', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03918f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass  Survived  SexCode\n",
       "0                   Allen, Miss Elisabeth Walton    1st         1        1\n",
       "1                    Allison, Miss Helen Loraine    1st         0        1\n",
       "2            Allison, Mr Hudson Joshua Creighton    1st         0        0\n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st         0        1\n",
       "4                  Allison, Master Hudson Trevor    1st         1        0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete multiple columns\n",
    "\n",
    "dataframe.drop(['Age','Sex'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b329dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'PClass', 'Age', 'Sex', 'Survived', 'SexCode'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fef4bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name    Age     Sex  Survived  \\\n",
       "0                   Allen, Miss Elisabeth Walton  29.00  female         1   \n",
       "1                    Allison, Miss Helen Loraine   2.00  female         0   \n",
       "2            Allison, Mr Hudson Joshua Creighton  30.00     NaN         0   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)  25.00  female         0   \n",
       "4                  Allison, Master Hudson Trevor   0.92     NaN         1   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns using index\n",
    "\n",
    "dataframe.drop(dataframe.columns[1],axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824b291",
   "metadata": {},
   "source": [
    "# deleting a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fe77637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass    Age     Sex  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "1                    Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.00     NaN   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                  Allison, Master Hudson Trevor    1st   0.92     NaN   \n",
       "\n",
       "   Survived  SexCode  \n",
       "0         1        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  \n",
       "4         1        0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete a row\n",
    "\n",
    "dataframe[dataframe['Sex'] != 'male'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a886838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anderson, Mr Harry</td>\n",
       "      <td>1st</td>\n",
       "      <td>47.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass    Age     Sex  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.00     NaN   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                  Allison, Master Hudson Trevor    1st   0.92     NaN   \n",
       "5                             Anderson, Mr Harry    1st  47.00     NaN   \n",
       "\n",
       "   Survived  SexCode  \n",
       "0         1        1  \n",
       "2         0        0  \n",
       "3         0        1  \n",
       "4         1        0  \n",
       "5         1        0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['Name'] != 'Allison, Miss Helen Loraine'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43a4e648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anderson, Mr Harry</td>\n",
       "      <td>1st</td>\n",
       "      <td>47.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass    Age     Sex  \\\n",
       "1                    Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.00     NaN   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                  Allison, Master Hudson Trevor    1st   0.92     NaN   \n",
       "5                             Anderson, Mr Harry    1st  47.00     NaN   \n",
       "\n",
       "   Survived  SexCode  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  \n",
       "4         1        0  \n",
       "5         1        0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe.index != 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505aaa1",
   "metadata": {},
   "source": [
    "#  Dropping duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ceb7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>3rd</td>\n",
       "      <td>27.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>3rd</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Zenni, Mr Philip</td>\n",
       "      <td>3rd</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Lievens, Mr Rene</td>\n",
       "      <td>3rd</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3rd</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Name PClass    Age     Sex  \\\n",
       "0                      Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "1                       Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2               Allison, Mr Hudson Joshua Creighton    1st  30.00     NaN   \n",
       "3     Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                     Allison, Master Hudson Trevor    1st   0.92     NaN   \n",
       "...                                             ...    ...    ...     ...   \n",
       "1308                             Zakarian, Mr Artun    3rd  27.00     NaN   \n",
       "1309                         Zakarian, Mr Maprieder    3rd  26.00     NaN   \n",
       "1310                               Zenni, Mr Philip    3rd  22.00     NaN   \n",
       "1311                               Lievens, Mr Rene    3rd  24.00     NaN   \n",
       "1312                                 Zimmerman, Leo    3rd  29.00     NaN   \n",
       "\n",
       "      Survived  SexCode  \n",
       "0            1        1  \n",
       "1            0        1  \n",
       "2            0        0  \n",
       "3            0        1  \n",
       "4            1        0  \n",
       "...        ...      ...  \n",
       "1308         0        0  \n",
       "1309         0        0  \n",
       "1310         0        0  \n",
       "1311         0        0  \n",
       "1312         0        0  \n",
       "\n",
       "[1313 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c80e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check\n",
    "\n",
    "len(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2055dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76573dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0     NaN         0        0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset fuction\n",
    "\n",
    "dataframe.drop_duplicates(subset=['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd514b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3rd</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name PClass   Age     Sex  Survived  SexCode\n",
       "1307  Zabour, Miss Tamini    3rd   NaN  female         0        1\n",
       "1312       Zimmerman, Leo    3rd  29.0     NaN         0        0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset fuction by using keep parameter\n",
    "\n",
    "dataframe.drop_duplicates(subset=['Sex'], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d7bb5",
   "metadata": {},
   "source": [
    "# Grouping Rows by Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce813bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    29.396424\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows by the values of the column 'Sex',  calculate mean of each group\n",
    "\n",
    "dataframe.groupby('Sex')['Age'].mean() # Note: Aggregate function should be used after the groupby function , otherwise itll not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e981438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002623915D540>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eg\n",
    "\n",
    "dataframe.groupby('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1bc67a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    863\n",
       "1    450\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group rows, count rows\n",
    "\n",
    "dataframe.groupby('Survived')['Name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7e6311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0           24.901408\n",
       "        1           30.867143\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupby(['Sex','Survived'])['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34317cb8",
   "metadata": {},
   "source": [
    "# Grouping Rows by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3d95be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date range\n",
    "\n",
    "time_index = pd.date_range('06/06/2017', periods=100000, freq = '30s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a72677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "dataframe = pd.DataFrame(index=time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38c53480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of random values\n",
    "\n",
    "dataframe['Sale_Amount'] = np.random.randint(1, 10, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dcb99ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:30</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:30</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:02:00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sale_Amount\n",
       "2017-06-06 00:00:00            6\n",
       "2017-06-06 00:00:30            5\n",
       "2017-06-06 00:01:00            8\n",
       "2017-06-06 00:01:30            5\n",
       "2017-06-06 00:02:00            7"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8772a558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-10 17:17:30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 17:18:00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 17:18:30</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 17:19:00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 17:19:30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sale_Amount\n",
       "2017-07-10 17:17:30            4\n",
       "2017-07-10 17:18:00            8\n",
       "2017-07-10 17:18:30            5\n",
       "2017-07-10 17:19:00            9\n",
       "2017-07-10 17:19:30            4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce955cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>86117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>101091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>100557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-02</th>\n",
       "      <td>100844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>100653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>10230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11        86117\n",
       "2017-06-18       101091\n",
       "2017-06-25       100557\n",
       "2017-07-02       100844\n",
       "2017-07-09       100653\n",
       "2017-07-16        10230"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows by week, calculate sum per week\n",
    "\n",
    "dataframe.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "444574f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>4.983623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>5.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>4.997445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-23</th>\n",
       "      <td>4.918269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11     4.983623\n",
       "2017-06-25     5.001190\n",
       "2017-07-09     4.997445\n",
       "2017-07-23     4.918269"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by two weeks, calculate mean\n",
    "\n",
    "dataframe.resample('2W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "671768f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>86117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>201648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>201497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-23</th>\n",
       "      <td>10230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11        86117\n",
       "2017-06-25       201648\n",
       "2017-07-09       201497\n",
       "2017-07-23        10230"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.resample('2W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ae8a3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-30        72000\n",
       "2017-07-31        28000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by month, count rows\n",
    "\n",
    "dataframe.resample('M').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "574977b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-05-31        72000\n",
       "2017-06-30        28000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by month, count rows\n",
    "\n",
    "dataframe.resample('M', label='left').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613dc861",
   "metadata": {},
   "source": [
    "#  Looping over a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "146491fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass    Age     Sex  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
       "1                    Allison, Miss Helen Loraine    1st   2.00  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.00    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
       "4                  Allison, Master Hudson Trevor    1st   0.92    male   \n",
       "\n",
       "   Survived  SexCode  \n",
       "0         1        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  \n",
       "4         1        0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create url\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
    "\n",
    "# load data as dataframe\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# to get the first 5 rows\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a5d1f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEN, MISS ELISABETH WALTON\n",
      "ALLISON, MISS HELEN LORAINE\n"
     ]
    }
   ],
   "source": [
    "# print the first two roes in upper case\n",
    "\n",
    "for i in dataframe['Name'][0:2]:\n",
    "    print(i.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6ba4048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLEN, MISS ELISABETH WALTON', 'ALLISON, MISS HELEN LORAINE']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In addition to loops (often called for loops),  we can also use list comprehensions\n",
    "\n",
    "[i.upper() for i in dataframe['Name'][0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba284aed",
   "metadata": {},
   "source": [
    "# Applying a function over all elements in a column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb8eae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "\n",
    "def uppercase(x):\n",
    "    return x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb937a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ALLEN, MISS ELISABETH WALTON\n",
       "1     ALLISON, MISS HELEN LORAINE\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply function , show the first 3 rows\n",
    "\n",
    "dataframe['Name'].apply(uppercase)[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a9ffe",
   "metadata": {},
   "source": [
    "# Applying a Function to Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8abf449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>288</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>468</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  PClass  Age  Sex  Survived  SexCode\n",
       "Sex                                              \n",
       "female   462     462  288  462       462      462\n",
       "male     851     851  468  851       851      851"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows, apply function to groups\n",
    "\n",
    "dataframe.groupby('Sex').apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d709b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47f4211e",
   "metadata": {},
   "source": [
    "# Handling Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574362f",
   "metadata": {},
   "source": [
    "# Rescaling a feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "33016ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikit-learn's MinMaxScaler to rescale a feature array\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27e0f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# create feature\n",
    "\n",
    "Feature = np.array([[-500.5],\n",
    "                   [-100.1],\n",
    "                   [0],\n",
    "                   [100.1],\n",
    "                   [900.9]])\n",
    "\n",
    "# create scaler\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Scale feature\n",
    "\n",
    "scaled_feature = minmax_scale.fit_transform(Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dacabff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687ce19",
   "metadata": {},
   "source": [
    "# Standardizing a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa6ecc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library \n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Creating a feature\n",
    "\n",
    "X = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])\n",
    "\n",
    "# create scaler\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# transform the feature \n",
    "\n",
    "standardized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ecaf7492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d49cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0\n",
      "Standard Deviation 1.0\n"
     ]
    }
   ],
   "source": [
    "# to check if the standardization is correct or not\n",
    "\n",
    "# use their mean and standard deviation to confirm, because if we do satndardization we need to get mean as 0 and std as 1\n",
    "\n",
    "\n",
    "print('Mean', round(standardized.mean()))\n",
    "print('Standard Deviation', standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c059d5",
   "metadata": {},
   "source": [
    "If our data has significant outliers, it can negatively impact our standardization by affecting the fatures mean and variance.\n",
    "In this scenario, it is often helpful to instead rescale the feature using the median and quartile range. In scikit - learn, we do this using RobustScaler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8f4e416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Scaler\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# transform feature\n",
    "robust_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb586be0",
   "metadata": {},
   "source": [
    "# Normalizing Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb4110f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# create feature matrix\n",
    "\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]])\n",
    "\n",
    "# create normalizer \n",
    "normalizer = Normalizer(norm = 'l2')\n",
    "\n",
    "# transform feature matrix\n",
    "\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca2e80",
   "metadata": {},
   "source": [
    "Alternatively we can specify Manhattan norm('l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "317358a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform feature matrix\n",
    "features_11_norm = Normalizer(norm='l1').transform(features)\n",
    "\n",
    "# show feature matrix\n",
    "features_11_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0a103ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_l1_norm = Normalizer(norm='l1')\n",
    "features_l1_norm.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check, \n",
    "\n",
    "print('Sum of the first observation\\'s values:', \n",
    "     features_11_norm[0, 0] + features_11_norm[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490dfcc",
   "metadata": {},
   "source": [
    "# Generating Polynomial and Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948114e",
   "metadata": {},
   "source": [
    "Even though some choose to create polynomial and interaction features manually, scikit-learn offers a built-in method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ac02550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ba3a1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features\n",
    "\n",
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c329b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create polynominal features object \n",
    "\n",
    "polynominal_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# create polynominal features\n",
    "polynominal_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "378a952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can restrict the features created to only interaction features by setting interaction_only to True\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2,\n",
    "interaction_only = True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b58fc7",
   "metadata": {},
   "source": [
    "# Transforming Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7642fc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# create a feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])\n",
    "\n",
    "# Define a simple function\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "# Create transformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "# Transform feature matrix\n",
    "ten_transformer.transform(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d6c17",
   "metadata": {},
   "source": [
    "we can create the same transformation in pandas using apply method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd60c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "66c9480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "# apply function\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042161b3",
   "metadata": {},
   "source": [
    "#  Dectecting Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e5242b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# create stimulated data\n",
    "\n",
    "features, _ = make_blobs(n_samples=10,\n",
    "                        n_features=2,\n",
    "                        centers=1,\n",
    "                        random_state=1)\n",
    "\n",
    "# Replace the first observation with extreme values\n",
    "\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "# fit detector\n",
    "\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "# Predict outliers\n",
    "\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7478ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0], dtype=int64), array([0, 1], dtype=int64))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use interquartile range (IQR)\n",
    "\n",
    "def indices_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "# run function\n",
    "\n",
    "indices_of_outliers(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01d3b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d28be356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+04, -2.76017908e+00, -1.61734616e+00, -5.25790464e-01,\n",
       "        8.52518583e-02, -7.94152277e-01, -1.34052081e+00, -1.98197711e+00,\n",
       "       -2.18773166e+00, -1.97451969e-01])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f1de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "838183b3",
   "metadata": {},
   "source": [
    "# Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    " # we have three strategies to handle the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e37687d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we can drop them\n",
    "\n",
    "# load library\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# craete dataframe\n",
    "\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_feet'] = [1500, 2500, 1500, 40000]\n",
    "\n",
    "# filter obsevation\n",
    "\n",
    "houses[houses['Bathrooms'] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d5b21a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_feet  Outlier\n",
       "0   534433        2.0         1500        0\n",
       "1   392333        3.5         2500        0\n",
       "2   293222        2.0         1500        0\n",
       "3  4322032      116.0        40000        1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second stratergey, we can mark them as a oulier and include it as a feature\n",
    "\n",
    "# load library\n",
    "import numpy as np\n",
    "\n",
    "# Create feature based on boolean condition\n",
    "houses['Outlier'] = np.where(houses['Bathrooms']<20,0,1)\n",
    "\n",
    "# show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1efd7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.596635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_feet  Outlier  Log_of_Square_Feet\n",
       "0   534433        2.0         1500        0            7.313220\n",
       "1   392333        3.5         2500        0            7.824046\n",
       "2   293222        2.0         1500        0            7.313220\n",
       "3  4322032      116.0        40000        1           10.596635"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we can transform the feature to dampen the effect of the outlier\n",
    "\n",
    "# Log feature\n",
    "houses['Log_of_Square_Feet'] = [np.log(x) for x in houses['Square_feet']]\n",
    "\n",
    "# show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de2da5",
   "metadata": {},
   "source": [
    "# Discretizating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5218972",
   "metadata": {},
   "source": [
    "Depending upon how you want to break up the data, thre are two techniques we can use.\n",
    "1) we can binarize the feature according to some threshold\n",
    "2) We can digitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3539ecc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Binarizer.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [120], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m age \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m6\u001b[39m],\n\u001b[0;32m      7\u001b[0m                [\u001b[38;5;241m12\u001b[39m],\n\u001b[0;32m      8\u001b[0m                [\u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m      9\u001b[0m                [\u001b[38;5;241m36\u001b[39m],\n\u001b[0;32m     10\u001b[0m                [\u001b[38;5;241m65\u001b[39m]])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# create binarizer\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m binarizer \u001b[38;5;241m=\u001b[39m \u001b[43mBinarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# transform feature\u001b[39;00m\n\u001b[0;32m     16\u001b[0m binarizer\u001b[38;5;241m.\u001b[39mfit_transform(age)\n",
      "\u001b[1;31mTypeError\u001b[0m: Binarizer.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# creating a feature\n",
    "age = np.array([[6],\n",
    "               [12],\n",
    "               [20],\n",
    "               [36],\n",
    "               [65]])\n",
    "\n",
    "# create binarizer\n",
    "binarizer = Binarizer(18)\n",
    "\n",
    "# transform feature\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01261faf",
   "metadata": {},
   "source": [
    "Second we can break up numerical features according to multiple thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d32e36c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin feature\n",
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146da20",
   "metadata": {},
   "source": [
    "# Grouping observations using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fecba232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamilarasu16\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.794152</td>\n",
       "      <td>2.104951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.760179</td>\n",
       "      <td>5.551214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.946905</td>\n",
       "      <td>-4.590344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.525790</td>\n",
       "      <td>3.306599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.981977</td>\n",
       "      <td>4.022436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.865964</td>\n",
       "      <td>-7.968072</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-6.834787</td>\n",
       "      <td>-7.391217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-6.749247</td>\n",
       "      <td>-10.175429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-10.752110</td>\n",
       "      <td>-2.700480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-8.508996</td>\n",
       "      <td>-8.657694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.330806</td>\n",
       "      <td>4.393825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.197452</td>\n",
       "      <td>2.346349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.085252</td>\n",
       "      <td>3.645283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-10.206607</td>\n",
       "      <td>-3.366725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-9.158729</td>\n",
       "      <td>-3.022246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.340521</td>\n",
       "      <td>4.157119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.831988</td>\n",
       "      <td>3.528631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-9.806797</td>\n",
       "      <td>-1.853093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.758704</td>\n",
       "      <td>3.722762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-11.140231</td>\n",
       "      <td>-4.302691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-7.812137</td>\n",
       "      <td>-5.349845</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.351221</td>\n",
       "      <td>4.009736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-6.878321</td>\n",
       "      <td>-7.743176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.782450</td>\n",
       "      <td>3.470720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-7.371086</td>\n",
       "      <td>-7.325253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-7.735544</td>\n",
       "      <td>-7.775664</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-11.115023</td>\n",
       "      <td>-3.718933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-9.697542</td>\n",
       "      <td>-4.305598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-10.189548</td>\n",
       "      <td>-4.840978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-2.187732</td>\n",
       "      <td>3.333521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-2.346733</td>\n",
       "      <td>3.561284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.927448</td>\n",
       "      <td>4.936845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-10.744871</td>\n",
       "      <td>-2.260894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-6.866582</td>\n",
       "      <td>-8.034219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-7.512011</td>\n",
       "      <td>-6.928720</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-6.904845</td>\n",
       "      <td>-7.277059</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1.617346</td>\n",
       "      <td>4.989305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.757969</td>\n",
       "      <td>4.908984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-9.484783</td>\n",
       "      <td>-4.251441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-7.408736</td>\n",
       "      <td>-8.109631</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-9.509194</td>\n",
       "      <td>-4.028920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-8.337910</td>\n",
       "      <td>-3.211304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-9.712125</td>\n",
       "      <td>-3.068207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-8.866083</td>\n",
       "      <td>-2.433532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-7.684883</td>\n",
       "      <td>-7.455196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_1  feature_2  Group\n",
       "0   -9.877554  -3.336145      0\n",
       "1   -7.287210  -8.353986      2\n",
       "2   -6.943061  -7.023744      2\n",
       "3   -7.440167  -8.791959      2\n",
       "4   -6.641388  -8.075888      2\n",
       "5   -0.794152   2.104951      1\n",
       "6   -2.760179   5.551214      1\n",
       "7   -9.946905  -4.590344      0\n",
       "8   -0.525790   3.306599      1\n",
       "9   -1.981977   4.022436      1\n",
       "10  -5.865964  -7.968072      2\n",
       "11  -6.834787  -7.391217      2\n",
       "12  -6.749247 -10.175429      2\n",
       "13 -10.752110  -2.700480      0\n",
       "14  -8.508996  -8.657694      2\n",
       "15  -2.330806   4.393825      1\n",
       "16  -0.197452   2.346349      1\n",
       "17   0.085252   3.645283      1\n",
       "18 -10.206607  -3.366725      0\n",
       "19  -9.158729  -3.022246      0\n",
       "20  -1.340521   4.157119      1\n",
       "21  -1.831988   3.528631      1\n",
       "22  -9.806797  -1.853093      0\n",
       "23  -0.758704   3.722762      1\n",
       "24 -11.140231  -4.302691      0\n",
       "25  -7.812137  -5.349845      2\n",
       "26  -2.351221   4.009736      1\n",
       "27  -6.878321  -7.743176      2\n",
       "28  -1.782450   3.470720      1\n",
       "29  -7.371086  -7.325253      2\n",
       "30  -7.735544  -7.775664      2\n",
       "31 -11.115023  -3.718933      0\n",
       "32  -9.697542  -4.305598      0\n",
       "33 -10.189548  -4.840978      0\n",
       "34  -2.187732   3.333521      1\n",
       "35  -2.346733   3.561284      1\n",
       "36  -1.927448   4.936845      1\n",
       "37 -10.744871  -2.260894      0\n",
       "38  -6.866582  -8.034219      2\n",
       "39  -7.512011  -6.928720      2\n",
       "40  -6.904845  -7.277059      2\n",
       "41  -1.617346   4.989305      1\n",
       "42  -0.757969   4.908984      1\n",
       "43  -9.484783  -4.251441      0\n",
       "44  -7.408736  -8.109631      2\n",
       "45  -9.509194  -4.028920      0\n",
       "46  -8.337910  -3.211304      0\n",
       "47  -9.712125  -3.068207      0\n",
       "48  -8.866083  -2.433532      0\n",
       "49  -7.684883  -7.455196      2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# make stimulated feature matrix\n",
    "features, _ = make_blobs(n_samples=50,\n",
    "                        n_features=2,\n",
    "                        centers=3,\n",
    "                        random_state=1)\n",
    "\n",
    "# create dataframe\n",
    "dataframe = pd.DataFrame(features, columns = ['feature_1', 'feature_2'])\n",
    "\n",
    "# make K means cluster\n",
    "cluster = KMeans(3, random_state=0)\n",
    "\n",
    "# fit cluster\n",
    "cluster.fit(features)\n",
    "\n",
    "# Predict values\n",
    "dataframe['Group'] = cluster.predict(features)\n",
    "\n",
    "# show observation\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191bc2a",
   "metadata": {},
   "source": [
    "# Deleting Observations with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e175ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamilarasu16\\AppData\\Local\\Temp\\ipykernel_11796\\320422134.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features = np.array([[1.1, 11,1],\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [123], line 15\u001b[0m\n\u001b[0;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      8\u001b[0m                     [\u001b[38;5;241m2.2\u001b[39m, \u001b[38;5;241m22.2\u001b[39m],\n\u001b[0;32m      9\u001b[0m                     [\u001b[38;5;241m3.3\u001b[39m, \u001b[38;5;241m33.3\u001b[39m],\n\u001b[0;32m     10\u001b[0m                     [\u001b[38;5;241m4.4\u001b[39m, \u001b[38;5;241m44.4\u001b[39m],\n\u001b[0;32m     11\u001b[0m                     [np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;241m55\u001b[39m]])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# keep only observations that are not (denoted by ~) missing\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m features[\u001b[38;5;241m~\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# you need to delete the observations which are containing missing values\n",
    "\n",
    "# Load library\n",
    "import numpy as np\n",
    "\n",
    "# create feature matrix\n",
    "features = np.array([[1.1, 11,1],\n",
    "                    [2.2, 22.2],\n",
    "                    [3.3, 33.3],\n",
    "                    [4.4, 44.4],\n",
    "                    [np.nan, 55]])\n",
    "\n",
    "# keep only observations that are not (denoted by ~) missing\n",
    "\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cbbdb9af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 1), indices imply (5, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [124], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# remove the missing values in the dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:720\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    710\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    711\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    712\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    717\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    718\u001b[0m         )\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (5, 1), indices imply (5, 2)"
     ]
    }
   ],
   "source": [
    "# alternatively we can drop the missing values by using pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "dataframe = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "# remove the missing values in the dataset\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1a336",
   "metadata": {},
   "source": [
    "# handling Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0b3be",
   "metadata": {},
   "source": [
    "It is a qualitative data and it has two types\n",
    "1. nominal--> No ordering\n",
    "2. ordinal--> we can see natural ordering in this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dd92b",
   "metadata": {},
   "source": [
    "# Encoding Nominal Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365362e",
   "metadata": {},
   "source": [
    "  you have a feature with nominal classes that has no intrinstic ordering (eg) apple, pear, banana\n",
    "  one hot encode the feature using scikit learns LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38982e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "848478e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature\n",
    "feature = np.array([['Texas'],\n",
    "                   ['California'],\n",
    "                   ['Texas'],\n",
    "                   ['Delaware'],\n",
    "                   ['Texas']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "512ef843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "# Fit one hot encode feature\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1514ac",
   "metadata": {},
   "source": [
    "we can use the class method to output the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9d03c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view feature classes\n",
    "\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ce117",
   "metadata": {},
   "source": [
    "If we want to reverse the one hot encoding we can use inverse_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e6901498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse one hot encoding\n",
    "\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553ee02",
   "metadata": {},
   "source": [
    "We can even use pandas to one-hot encode the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4365453c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "\n",
    "# create dummy variables from feature\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376b1ff",
   "metadata": {},
   "source": [
    "one helpful ability of scikit learn is to handle a situation where each observation lists multiple classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9edf966f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create multiclass feature\n",
    "\n",
    "multiclass_feature = [('Texas', 'Florida'),\n",
    "                     ('California', 'Alabama'),\n",
    "                     ('Texas', 'Florida'),\n",
    "                     ('Delaware', 'Florida'),\n",
    "                     ('Texas', 'Alabama')]\n",
    "\n",
    "# create multiclass one hot encoder\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "# One_hot_multiclass featue\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8acfb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delaware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view classes\n",
    "\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1b40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf69f1a9",
   "metadata": {},
   "source": [
    "# Encoding Ordinal Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef5de6",
   "metadata": {},
   "source": [
    "Use Pandas DataFrame's replace method to transform string labels to numerical equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb0a9555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create feature\n",
    "dataframe = pd.DataFrame({'Score': ['Low', 'Low', 'Medium', 'Medium', 'High']})\n",
    "\n",
    "# create mapper\n",
    "scale_mapper = {'Low':1,\n",
    "               'Medium':2,\n",
    "               'High':3}\n",
    "\n",
    "# Replace feature values with scale\n",
    "dataframe['Score'].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b528b8",
   "metadata": {},
   "source": [
    "# Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0dacbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# create dictionary\n",
    "data_dict = [{'Red':2, 'Blue':4},\n",
    "            {'Red':4, 'Blue':3},\n",
    "            {'Red':1, 'Yellow':2},\n",
    "            {'Red':2, 'Yellow':2}]\n",
    "\n",
    "# create dictionary vectorizer\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "# to get the feature matrix\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de6d1e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if we use sparse = true\n",
    "\n",
    "# import library\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# create dictionary\n",
    "data_dict = [{'Red':2, 'Blue':4},\n",
    "            {'Red':4, 'Blue':3},\n",
    "            {'Red':1, 'Yellow':2},\n",
    "            {'Red':2, 'Yellow':2}]\n",
    "\n",
    "# create dictionary vectoorizer\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=True)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "# to get the feature matrix\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a995ca53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blue', 'Red', 'Yellow'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the feature names\n",
    "\n",
    "feature_names = dictvectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f67de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f92cde",
   "metadata": {},
   "source": [
    "# Imputing Missing Class Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "             [1, 1.18, 1.33],\n",
    "             [0, 1.22, 1.27],\n",
    "             [1, -0.21, -1.19]])\n",
    "\n",
    "print(X[:,1:])\n",
    "print(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e79e8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create feature matrix with missing values in the categorical feature\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "             [1, 1.18, 1.33],\n",
    "             [0, 1.22, 1.27],\n",
    "             [1, -0.21, -1.19]])\n",
    "\n",
    "# create feature matrix with missing values in the categorial feature\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                      [np.nan, -0.67, -0.22]])\n",
    "\n",
    "# train KNN learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:, 0])\n",
    "\n",
    "# predict missing value class\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22032ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bf016983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "51819a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join column of predicted class with their features\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "943c4f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7109f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join two feature matrices\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7fbd7adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to know about hstack and vstack\n",
    "# Vstack\n",
    "a = np.ones((3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7d833ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 2., 2.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array((2,2,2))\n",
    "\n",
    "np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "25f1af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hstack\n",
    "\n",
    "a = np.ones((3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array((2,2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "901dafb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [148], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c92e5012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it will throw an error, because we can't add here directly. we need to reshape it\n",
    "\n",
    "b = np.array((2,2,2)).reshape(3,1)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd34fc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 2.],\n",
       "       [1., 1., 1., 2.],\n",
       "       [1., 1., 1., 2.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c9550",
   "metadata": {},
   "source": [
    "An alternative solution is to fill in missing values with the features most frequent value by using Simple imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af552efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the required library\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# join the two feature matrix\n",
    "\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9d729f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  nan,  0.87,  1.31],\n",
       "       [  nan, -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980962d9",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1fcadbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "# creat target vector\n",
    "target = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "42a6a1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "51fd2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "44970826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove first 40  observations\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# create binary target vector indicating if class 0\n",
    "target = np.where((target  == 0), 0, 1)\n",
    "\n",
    "# look at the imbalanced target vector\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b7db44cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to balanance the imbalanced dataset\n",
    "\n",
    "# create weights\n",
    "weights = {0:0.9, 1:0.1}\n",
    "\n",
    "# create random forest classifier with weights\n",
    "RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3a8db45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you feel your dataset is balanced, then you can use the following\n",
    "\n",
    "# train a random forest with balanced class weights\n",
    "RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed13612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sampling and uosampling can be done for balamce the imbalamced data\n",
    "\n",
    "# Down sampling will on the majarity data\n",
    "# up sampling will be on the minority data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "846dd82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of each class observations\n",
    "\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "05384d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c88cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,\n",
       "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
       "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
       "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
       "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
       "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b618b450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = len(i_class0)\n",
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d2cdc654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = len(i_class1)\n",
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "673f2f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65,  38,  77,  68,  86, 103,  71,  15,  91,  82], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for every observation of class o, randomly sample\n",
    "# from class 1 without replacement\n",
    "\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "i_class1_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75f5a482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature vector with the downloaded class 1's target vector\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7d3255a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join together class 0's feature matrix with the downsampled class 1's feature matrix\n",
    "\n",
    "np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6dbfc736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, 7, 6, 1, 7, 3, 8, 2, 0, 1, 7, 5, 4, 2, 1, 9, 3, 4, 9, 2,\n",
       "       0, 9, 6, 3, 5, 8, 0, 2, 9, 1, 5, 7, 6, 4, 0, 0, 7, 2, 0, 7, 1, 0,\n",
       "       6, 8, 8, 1, 9, 2, 6, 2, 9, 4, 9, 6, 2, 4, 1, 9, 0, 3, 7, 1, 9, 0,\n",
       "       3, 7, 1, 7, 7, 5, 9, 4, 1, 9, 7, 5, 3, 3, 6, 4, 2, 2, 7, 1, 0, 4,\n",
       "       4, 7, 6, 5, 1, 8, 8, 6, 7, 0, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the other option upsampling the minority class\n",
    "\n",
    "# for every observation in class 1, randomly sample from class 0 with replacement\n",
    "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "i_class0_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d77d951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join together class 0's unsampled target vector with class 1's target vector\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2737e431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 3. , 1.4, 0.3],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join together class 0's upsampled features matrix with class 1's feature matrix\n",
    "np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b3752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a89165b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature vector with the downloaded class 1's target vector\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d5b0a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature vector with the downloaded class 1's target vector\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "02f54ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature vector with the downloaded class 1's target vector\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "90027de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature vector with the downloaded class 1's target vector\n",
    "\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5df08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3a18cec",
   "metadata": {},
   "source": [
    "# Handling Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6658548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python's core string operations, in particular strip, replace, and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a106416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text\n",
    "\n",
    "text_data = [' Interrobang. By Aishwarya Henriette ',\n",
    "            'Parking And Going. By Karl Gautier',\n",
    "            ' Today Is The night. By Jarek Prakash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05316064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip whitespaces\n",
    "strip_whitespace = [i.strip() for i in text_data]\n",
    "\n",
    "# show text\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text_data:\n",
    "    print(i.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove periods\n",
    "remove_periods = [i.replace('.','') for i in strip_whitespace]\n",
    "\n",
    "# show text\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640585d",
   "metadata": {},
   "source": [
    "We also create and apply a custom transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79686054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "def capitalizer(string: str) -> str:\n",
    "    return string.upper()\n",
    "\n",
    "# apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in remove_periods:\n",
    "    print(i.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we can use regular expressions to make powerfull string operations\n",
    "\n",
    "# Import library\n",
    "import re\n",
    "\n",
    "# create function\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r'[a-zA-Z]', 'X', string)\n",
    "\n",
    "#apply function\n",
    "[replace_letters_with_X(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5556b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we can use regular expressions to make powerfull string operations\n",
    "\n",
    "# Import library\n",
    "import re\n",
    "\n",
    "# create function\n",
    "def replace_letters_with_star(string: str) -> str:\n",
    "    return re.sub(r'[a-zA-Z]', '*', string)\n",
    "\n",
    "#apply function\n",
    "[replace_letters_with_star(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678717f",
   "metadata": {},
   "source": [
    "# Parsing and Cleaning HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e47b2",
   "metadata": {},
   "source": [
    "You have a text data with HTML, elements and want to extract just the text. Use Beautiful Soup's extensive set of options to parse and extract from HTML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf293839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\tamilarasu16\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf6b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\tamilarasu16\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (23.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dfd1431",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# find the div with the class 'full_name', show text\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# create some HTML code\n",
    "html = '''\n",
    "        <div class='ful_name'><span style='font-weight:bold'>\n",
    "        Masego</span> Azra</div>\n",
    "        '''\n",
    "\n",
    "#parse html\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# find the div with the class 'full_name', show text\n",
    "soup.find('div', {'class' : 'full_name'}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5791a1",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed719d73",
   "metadata": {},
   "source": [
    "Define a function that uses translate with a dictionary of punctuation characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abfa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# create a text\n",
    "text_data = ['Hi!!!! I. Love. Song....',\n",
    "            '10000% Agree!!!! #LoveIT',\n",
    "             'Right?!?!']\n",
    "\n",
    "# create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "             \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6deee9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 44: None,\n",
       " 45: None,\n",
       " 46: None,\n",
       " 47: None,\n",
       " 58: None,\n",
       " 59: None,\n",
       " 63: None,\n",
       " 64: None,\n",
       " 91: None,\n",
       " 92: None,\n",
       " 93: None,\n",
       " 95: None,\n",
       " 123: None,\n",
       " 125: None,\n",
       " 161: None,\n",
       " 167: None,\n",
       " 171: None,\n",
       " 182: None,\n",
       " 183: None,\n",
       " 187: None,\n",
       " 191: None,\n",
       " 894: None,\n",
       " 903: None,\n",
       " 1370: None,\n",
       " 1371: None,\n",
       " 1372: None,\n",
       " 1373: None,\n",
       " 1374: None,\n",
       " 1375: None,\n",
       " 1417: None,\n",
       " 1418: None,\n",
       " 1470: None,\n",
       " 1472: None,\n",
       " 1475: None,\n",
       " 1478: None,\n",
       " 1523: None,\n",
       " 1524: None,\n",
       " 1545: None,\n",
       " 1546: None,\n",
       " 1548: None,\n",
       " 1549: None,\n",
       " 1563: None,\n",
       " 1566: None,\n",
       " 1567: None,\n",
       " 1642: None,\n",
       " 1643: None,\n",
       " 1644: None,\n",
       " 1645: None,\n",
       " 1748: None,\n",
       " 1792: None,\n",
       " 1793: None,\n",
       " 1794: None,\n",
       " 1795: None,\n",
       " 1796: None,\n",
       " 1797: None,\n",
       " 1798: None,\n",
       " 1799: None,\n",
       " 1800: None,\n",
       " 1801: None,\n",
       " 1802: None,\n",
       " 1803: None,\n",
       " 1804: None,\n",
       " 1805: None,\n",
       " 2039: None,\n",
       " 2040: None,\n",
       " 2041: None,\n",
       " 2096: None,\n",
       " 2097: None,\n",
       " 2098: None,\n",
       " 2099: None,\n",
       " 2100: None,\n",
       " 2101: None,\n",
       " 2102: None,\n",
       " 2103: None,\n",
       " 2104: None,\n",
       " 2105: None,\n",
       " 2106: None,\n",
       " 2107: None,\n",
       " 2108: None,\n",
       " 2109: None,\n",
       " 2110: None,\n",
       " 2142: None,\n",
       " 2404: None,\n",
       " 2405: None,\n",
       " 2416: None,\n",
       " 2557: None,\n",
       " 2678: None,\n",
       " 2800: None,\n",
       " 3191: None,\n",
       " 3204: None,\n",
       " 3572: None,\n",
       " 3663: None,\n",
       " 3674: None,\n",
       " 3675: None,\n",
       " 3844: None,\n",
       " 3845: None,\n",
       " 3846: None,\n",
       " 3847: None,\n",
       " 3848: None,\n",
       " 3849: None,\n",
       " 3850: None,\n",
       " 3851: None,\n",
       " 3852: None,\n",
       " 3853: None,\n",
       " 3854: None,\n",
       " 3855: None,\n",
       " 3856: None,\n",
       " 3857: None,\n",
       " 3858: None,\n",
       " 3860: None,\n",
       " 3898: None,\n",
       " 3899: None,\n",
       " 3900: None,\n",
       " 3901: None,\n",
       " 3973: None,\n",
       " 4048: None,\n",
       " 4049: None,\n",
       " 4050: None,\n",
       " 4051: None,\n",
       " 4052: None,\n",
       " 4057: None,\n",
       " 4058: None,\n",
       " 4170: None,\n",
       " 4171: None,\n",
       " 4172: None,\n",
       " 4173: None,\n",
       " 4174: None,\n",
       " 4175: None,\n",
       " 4347: None,\n",
       " 4960: None,\n",
       " 4961: None,\n",
       " 4962: None,\n",
       " 4963: None,\n",
       " 4964: None,\n",
       " 4965: None,\n",
       " 4966: None,\n",
       " 4967: None,\n",
       " 4968: None,\n",
       " 5120: None,\n",
       " 5742: None,\n",
       " 5787: None,\n",
       " 5788: None,\n",
       " 5867: None,\n",
       " 5868: None,\n",
       " 5869: None,\n",
       " 5941: None,\n",
       " 5942: None,\n",
       " 6100: None,\n",
       " 6101: None,\n",
       " 6102: None,\n",
       " 6104: None,\n",
       " 6105: None,\n",
       " 6106: None,\n",
       " 6144: None,\n",
       " 6145: None,\n",
       " 6146: None,\n",
       " 6147: None,\n",
       " 6148: None,\n",
       " 6149: None,\n",
       " 6150: None,\n",
       " 6151: None,\n",
       " 6152: None,\n",
       " 6153: None,\n",
       " 6154: None,\n",
       " 6468: None,\n",
       " 6469: None,\n",
       " 6686: None,\n",
       " 6687: None,\n",
       " 6816: None,\n",
       " 6817: None,\n",
       " 6818: None,\n",
       " 6819: None,\n",
       " 6820: None,\n",
       " 6821: None,\n",
       " 6822: None,\n",
       " 6824: None,\n",
       " 6825: None,\n",
       " 6826: None,\n",
       " 6827: None,\n",
       " 6828: None,\n",
       " 6829: None,\n",
       " 7002: None,\n",
       " 7003: None,\n",
       " 7004: None,\n",
       " 7005: None,\n",
       " 7006: None,\n",
       " 7007: None,\n",
       " 7008: None,\n",
       " 7164: None,\n",
       " 7165: None,\n",
       " 7166: None,\n",
       " 7167: None,\n",
       " 7227: None,\n",
       " 7228: None,\n",
       " 7229: None,\n",
       " 7230: None,\n",
       " 7231: None,\n",
       " 7294: None,\n",
       " 7295: None,\n",
       " 7360: None,\n",
       " 7361: None,\n",
       " 7362: None,\n",
       " 7363: None,\n",
       " 7364: None,\n",
       " 7365: None,\n",
       " 7366: None,\n",
       " 7367: None,\n",
       " 7379: None,\n",
       " 8208: None,\n",
       " 8209: None,\n",
       " 8210: None,\n",
       " 8211: None,\n",
       " 8212: None,\n",
       " 8213: None,\n",
       " 8214: None,\n",
       " 8215: None,\n",
       " 8216: None,\n",
       " 8217: None,\n",
       " 8218: None,\n",
       " 8219: None,\n",
       " 8220: None,\n",
       " 8221: None,\n",
       " 8222: None,\n",
       " 8223: None,\n",
       " 8224: None,\n",
       " 8225: None,\n",
       " 8226: None,\n",
       " 8227: None,\n",
       " 8228: None,\n",
       " 8229: None,\n",
       " 8230: None,\n",
       " 8231: None,\n",
       " 8240: None,\n",
       " 8241: None,\n",
       " 8242: None,\n",
       " 8243: None,\n",
       " 8244: None,\n",
       " 8245: None,\n",
       " 8246: None,\n",
       " 8247: None,\n",
       " 8248: None,\n",
       " 8249: None,\n",
       " 8250: None,\n",
       " 8251: None,\n",
       " 8252: None,\n",
       " 8253: None,\n",
       " 8254: None,\n",
       " 8255: None,\n",
       " 8256: None,\n",
       " 8257: None,\n",
       " 8258: None,\n",
       " 8259: None,\n",
       " 8261: None,\n",
       " 8262: None,\n",
       " 8263: None,\n",
       " 8264: None,\n",
       " 8265: None,\n",
       " 8266: None,\n",
       " 8267: None,\n",
       " 8268: None,\n",
       " 8269: None,\n",
       " 8270: None,\n",
       " 8271: None,\n",
       " 8272: None,\n",
       " 8273: None,\n",
       " 8275: None,\n",
       " 8276: None,\n",
       " 8277: None,\n",
       " 8278: None,\n",
       " 8279: None,\n",
       " 8280: None,\n",
       " 8281: None,\n",
       " 8282: None,\n",
       " 8283: None,\n",
       " 8284: None,\n",
       " 8285: None,\n",
       " 8286: None,\n",
       " 8317: None,\n",
       " 8318: None,\n",
       " 8333: None,\n",
       " 8334: None,\n",
       " 8968: None,\n",
       " 8969: None,\n",
       " 8970: None,\n",
       " 8971: None,\n",
       " 9001: None,\n",
       " 9002: None,\n",
       " 10088: None,\n",
       " 10089: None,\n",
       " 10090: None,\n",
       " 10091: None,\n",
       " 10092: None,\n",
       " 10093: None,\n",
       " 10094: None,\n",
       " 10095: None,\n",
       " 10096: None,\n",
       " 10097: None,\n",
       " 10098: None,\n",
       " 10099: None,\n",
       " 10100: None,\n",
       " 10101: None,\n",
       " 10181: None,\n",
       " 10182: None,\n",
       " 10214: None,\n",
       " 10215: None,\n",
       " 10216: None,\n",
       " 10217: None,\n",
       " 10218: None,\n",
       " 10219: None,\n",
       " 10220: None,\n",
       " 10221: None,\n",
       " 10222: None,\n",
       " 10223: None,\n",
       " 10627: None,\n",
       " 10628: None,\n",
       " 10629: None,\n",
       " 10630: None,\n",
       " 10631: None,\n",
       " 10632: None,\n",
       " 10633: None,\n",
       " 10634: None,\n",
       " 10635: None,\n",
       " 10636: None,\n",
       " 10637: None,\n",
       " 10638: None,\n",
       " 10639: None,\n",
       " 10640: None,\n",
       " 10641: None,\n",
       " 10642: None,\n",
       " 10643: None,\n",
       " 10644: None,\n",
       " 10645: None,\n",
       " 10646: None,\n",
       " 10647: None,\n",
       " 10648: None,\n",
       " 10712: None,\n",
       " 10713: None,\n",
       " 10714: None,\n",
       " 10715: None,\n",
       " 10748: None,\n",
       " 10749: None,\n",
       " 11513: None,\n",
       " 11514: None,\n",
       " 11515: None,\n",
       " 11516: None,\n",
       " 11518: None,\n",
       " 11519: None,\n",
       " 11632: None,\n",
       " 11776: None,\n",
       " 11777: None,\n",
       " 11778: None,\n",
       " 11779: None,\n",
       " 11780: None,\n",
       " 11781: None,\n",
       " 11782: None,\n",
       " 11783: None,\n",
       " 11784: None,\n",
       " 11785: None,\n",
       " 11786: None,\n",
       " 11787: None,\n",
       " 11788: None,\n",
       " 11789: None,\n",
       " 11790: None,\n",
       " 11791: None,\n",
       " 11792: None,\n",
       " 11793: None,\n",
       " 11794: None,\n",
       " 11795: None,\n",
       " 11796: None,\n",
       " 11797: None,\n",
       " 11798: None,\n",
       " 11799: None,\n",
       " 11800: None,\n",
       " 11801: None,\n",
       " 11802: None,\n",
       " 11803: None,\n",
       " 11804: None,\n",
       " 11805: None,\n",
       " 11806: None,\n",
       " 11807: None,\n",
       " 11808: None,\n",
       " 11809: None,\n",
       " 11810: None,\n",
       " 11811: None,\n",
       " 11812: None,\n",
       " 11813: None,\n",
       " 11814: None,\n",
       " 11815: None,\n",
       " 11816: None,\n",
       " 11817: None,\n",
       " 11818: None,\n",
       " 11819: None,\n",
       " 11820: None,\n",
       " 11821: None,\n",
       " 11822: None,\n",
       " 11824: None,\n",
       " 11825: None,\n",
       " 11826: None,\n",
       " 11827: None,\n",
       " 11828: None,\n",
       " 11829: None,\n",
       " 11830: None,\n",
       " 11831: None,\n",
       " 11832: None,\n",
       " 11833: None,\n",
       " 11834: None,\n",
       " 11835: None,\n",
       " 11836: None,\n",
       " 11837: None,\n",
       " 11838: None,\n",
       " 11839: None,\n",
       " 11840: None,\n",
       " 11841: None,\n",
       " 11842: None,\n",
       " 11843: None,\n",
       " 11844: None,\n",
       " 11845: None,\n",
       " 11846: None,\n",
       " 11847: None,\n",
       " 11848: None,\n",
       " 11849: None,\n",
       " 11850: None,\n",
       " 11851: None,\n",
       " 11852: None,\n",
       " 11853: None,\n",
       " 11854: None,\n",
       " 11855: None,\n",
       " 11858: None,\n",
       " 12289: None,\n",
       " 12290: None,\n",
       " 12291: None,\n",
       " 12296: None,\n",
       " 12297: None,\n",
       " 12298: None,\n",
       " 12299: None,\n",
       " 12300: None,\n",
       " 12301: None,\n",
       " 12302: None,\n",
       " 12303: None,\n",
       " 12304: None,\n",
       " 12305: None,\n",
       " 12308: None,\n",
       " 12309: None,\n",
       " 12310: None,\n",
       " 12311: None,\n",
       " 12312: None,\n",
       " 12313: None,\n",
       " 12314: None,\n",
       " 12315: None,\n",
       " 12316: None,\n",
       " 12317: None,\n",
       " 12318: None,\n",
       " 12319: None,\n",
       " 12336: None,\n",
       " 12349: None,\n",
       " 12448: None,\n",
       " 12539: None,\n",
       " 42238: None,\n",
       " 42239: None,\n",
       " 42509: None,\n",
       " 42510: None,\n",
       " 42511: None,\n",
       " 42611: None,\n",
       " 42622: None,\n",
       " 42738: None,\n",
       " 42739: None,\n",
       " 42740: None,\n",
       " 42741: None,\n",
       " 42742: None,\n",
       " 42743: None,\n",
       " 43124: None,\n",
       " 43125: None,\n",
       " 43126: None,\n",
       " 43127: None,\n",
       " 43214: None,\n",
       " 43215: None,\n",
       " 43256: None,\n",
       " 43257: None,\n",
       " 43258: None,\n",
       " 43260: None,\n",
       " 43310: None,\n",
       " 43311: None,\n",
       " 43359: None,\n",
       " 43457: None,\n",
       " 43458: None,\n",
       " 43459: None,\n",
       " 43460: None,\n",
       " 43461: None,\n",
       " 43462: None,\n",
       " 43463: None,\n",
       " 43464: None,\n",
       " 43465: None,\n",
       " 43466: None,\n",
       " 43467: None,\n",
       " 43468: None,\n",
       " 43469: None,\n",
       " 43486: None,\n",
       " 43487: None,\n",
       " 43612: None,\n",
       " 43613: None,\n",
       " 43614: None,\n",
       " 43615: None,\n",
       " 43742: None,\n",
       " 43743: None,\n",
       " 43760: None,\n",
       " 43761: None,\n",
       " 44011: None,\n",
       " 64830: None,\n",
       " 64831: None,\n",
       " 65040: None,\n",
       " 65041: None,\n",
       " 65042: None,\n",
       " 65043: None,\n",
       " 65044: None,\n",
       " 65045: None,\n",
       " 65046: None,\n",
       " 65047: None,\n",
       " 65048: None,\n",
       " 65049: None,\n",
       " 65072: None,\n",
       " 65073: None,\n",
       " 65074: None,\n",
       " 65075: None,\n",
       " 65076: None,\n",
       " 65077: None,\n",
       " 65078: None,\n",
       " 65079: None,\n",
       " 65080: None,\n",
       " 65081: None,\n",
       " 65082: None,\n",
       " 65083: None,\n",
       " 65084: None,\n",
       " 65085: None,\n",
       " 65086: None,\n",
       " 65087: None,\n",
       " 65088: None,\n",
       " 65089: None,\n",
       " 65090: None,\n",
       " 65091: None,\n",
       " 65092: None,\n",
       " 65093: None,\n",
       " 65094: None,\n",
       " 65095: None,\n",
       " 65096: None,\n",
       " 65097: None,\n",
       " 65098: None,\n",
       " 65099: None,\n",
       " 65100: None,\n",
       " 65101: None,\n",
       " 65102: None,\n",
       " 65103: None,\n",
       " 65104: None,\n",
       " 65105: None,\n",
       " 65106: None,\n",
       " 65108: None,\n",
       " 65109: None,\n",
       " 65110: None,\n",
       " 65111: None,\n",
       " 65112: None,\n",
       " 65113: None,\n",
       " 65114: None,\n",
       " 65115: None,\n",
       " 65116: None,\n",
       " 65117: None,\n",
       " 65118: None,\n",
       " 65119: None,\n",
       " 65120: None,\n",
       " 65121: None,\n",
       " 65123: None,\n",
       " 65128: None,\n",
       " 65130: None,\n",
       " 65131: None,\n",
       " 65281: None,\n",
       " 65282: None,\n",
       " 65283: None,\n",
       " 65285: None,\n",
       " 65286: None,\n",
       " 65287: None,\n",
       " 65288: None,\n",
       " 65289: None,\n",
       " 65290: None,\n",
       " 65292: None,\n",
       " 65293: None,\n",
       " 65294: None,\n",
       " 65295: None,\n",
       " 65306: None,\n",
       " 65307: None,\n",
       " 65311: None,\n",
       " 65312: None,\n",
       " 65339: None,\n",
       " 65340: None,\n",
       " 65341: None,\n",
       " 65343: None,\n",
       " 65371: None,\n",
       " 65373: None,\n",
       " 65375: None,\n",
       " 65376: None,\n",
       " 65377: None,\n",
       " 65378: None,\n",
       " 65379: None,\n",
       " 65380: None,\n",
       " 65381: None,\n",
       " 65792: None,\n",
       " 65793: None,\n",
       " 65794: None,\n",
       " 66463: None,\n",
       " 66512: None,\n",
       " 66927: None,\n",
       " 67671: None,\n",
       " 67871: None,\n",
       " 67903: None,\n",
       " 68176: None,\n",
       " 68177: None,\n",
       " 68178: None,\n",
       " 68179: None,\n",
       " 68180: None,\n",
       " 68181: None,\n",
       " 68182: None,\n",
       " 68183: None,\n",
       " 68184: None,\n",
       " 68223: None,\n",
       " 68336: None,\n",
       " 68337: None,\n",
       " 68338: None,\n",
       " 68339: None,\n",
       " 68340: None,\n",
       " 68341: None,\n",
       " 68342: None,\n",
       " 68409: None,\n",
       " 68410: None,\n",
       " 68411: None,\n",
       " 68412: None,\n",
       " 68413: None,\n",
       " 68414: None,\n",
       " 68415: None,\n",
       " 68505: None,\n",
       " 68506: None,\n",
       " 68507: None,\n",
       " 68508: None,\n",
       " 69293: None,\n",
       " 69461: None,\n",
       " 69462: None,\n",
       " 69463: None,\n",
       " 69464: None,\n",
       " 69465: None,\n",
       " 69703: None,\n",
       " 69704: None,\n",
       " 69705: None,\n",
       " 69706: None,\n",
       " 69707: None,\n",
       " 69708: None,\n",
       " 69709: None,\n",
       " 69819: None,\n",
       " 69820: None,\n",
       " 69822: None,\n",
       " 69823: None,\n",
       " 69824: None,\n",
       " 69825: None,\n",
       " 69952: None,\n",
       " 69953: None,\n",
       " 69954: None,\n",
       " 69955: None,\n",
       " 70004: None,\n",
       " 70005: None,\n",
       " 70085: None,\n",
       " 70086: None,\n",
       " 70087: None,\n",
       " 70088: None,\n",
       " 70093: None,\n",
       " 70107: None,\n",
       " 70109: None,\n",
       " 70110: None,\n",
       " 70111: None,\n",
       " 70200: None,\n",
       " 70201: None,\n",
       " 70202: None,\n",
       " 70203: None,\n",
       " 70204: None,\n",
       " 70205: None,\n",
       " 70313: None,\n",
       " 70731: None,\n",
       " 70732: None,\n",
       " 70733: None,\n",
       " 70734: None,\n",
       " 70735: None,\n",
       " 70746: None,\n",
       " 70747: None,\n",
       " 70749: None,\n",
       " 70854: None,\n",
       " 71105: None,\n",
       " 71106: None,\n",
       " 71107: None,\n",
       " 71108: None,\n",
       " 71109: None,\n",
       " 71110: None,\n",
       " 71111: None,\n",
       " 71112: None,\n",
       " 71113: None,\n",
       " 71114: None,\n",
       " 71115: None,\n",
       " 71116: None,\n",
       " 71117: None,\n",
       " 71118: None,\n",
       " 71119: None,\n",
       " 71120: None,\n",
       " 71121: None,\n",
       " 71122: None,\n",
       " 71123: None,\n",
       " 71124: None,\n",
       " 71125: None,\n",
       " 71126: None,\n",
       " 71127: None,\n",
       " 71233: None,\n",
       " 71234: None,\n",
       " 71235: None,\n",
       " 71264: None,\n",
       " 71265: None,\n",
       " 71266: None,\n",
       " 71267: None,\n",
       " 71268: None,\n",
       " 71269: None,\n",
       " 71270: None,\n",
       " 71271: None,\n",
       " 71272: None,\n",
       " 71273: None,\n",
       " 71274: None,\n",
       " 71275: None,\n",
       " 71276: None,\n",
       " 71484: None,\n",
       " 71485: None,\n",
       " 71486: None,\n",
       " 71739: None,\n",
       " 72004: None,\n",
       " 72005: None,\n",
       " 72006: None,\n",
       " 72162: None,\n",
       " 72255: None,\n",
       " 72256: None,\n",
       " 72257: None,\n",
       " 72258: None,\n",
       " 72259: None,\n",
       " 72260: None,\n",
       " 72261: None,\n",
       " 72262: None,\n",
       " 72346: None,\n",
       " 72347: None,\n",
       " 72348: None,\n",
       " 72350: None,\n",
       " 72351: None,\n",
       " 72352: None,\n",
       " 72353: None,\n",
       " 72354: None,\n",
       " 72769: None,\n",
       " 72770: None,\n",
       " 72771: None,\n",
       " 72772: None,\n",
       " 72773: None,\n",
       " 72816: None,\n",
       " 72817: None,\n",
       " 73463: None,\n",
       " 73464: None,\n",
       " 73727: None,\n",
       " 74864: None,\n",
       " 74865: None,\n",
       " 74866: None,\n",
       " 74867: None,\n",
       " 74868: None,\n",
       " 92782: None,\n",
       " 92783: None,\n",
       " 92917: None,\n",
       " 92983: None,\n",
       " 92984: None,\n",
       " 92985: None,\n",
       " 92986: None,\n",
       " 92987: None,\n",
       " 92996: None,\n",
       " 93847: None,\n",
       " 93848: None,\n",
       " 93849: None,\n",
       " 93850: None,\n",
       " 94178: None,\n",
       " 113823: None,\n",
       " 121479: None,\n",
       " 121480: None,\n",
       " 121481: None,\n",
       " 121482: None,\n",
       " 121483: None,\n",
       " 125278: None,\n",
       " 125279: None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb27dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each string, remove any puncuation characters\n",
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c094e5c",
   "metadata": {},
   "source": [
    "# NLTK : Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8362fd",
   "metadata": {},
   "source": [
    "# Tokenizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ab516",
   "metadata": {},
   "source": [
    "Natural language toolkit for python(NLTK) has a powerful set of text manipulation operations, including word tokenzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eb24c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tamilarasu16\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install the required package\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ea7494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#create text\n",
    "text = 'The science of today is the technology of tomorrow'\n",
    "\n",
    "# tokenize words\n",
    "word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41cb366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also tokenize into sentences\n",
    "\n",
    "# load library\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# create text\n",
    "text = 'The science of today is the technology of tomorrow. Tomorrow is today.'\n",
    "\n",
    "# Tokenize sentences\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab62a8",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4810ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tamilarasu16\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "351ca8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# you will have to download set of stop words the first time\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# create word tokens\n",
    "\n",
    "tokenized_words = ['i',\n",
    "                  'am',\n",
    "                  'going',\n",
    "                  'to',\n",
    "                  'go',\n",
    "                  'to',\n",
    "                  'the',\n",
    "                  'store',\n",
    "                  'and',\n",
    "                  'park']\n",
    "\n",
    "# Load stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a67f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7400caa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'to', 'to', 'the', 'and']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in tokenized_words if word in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0af5e",
   "metadata": {},
   "source": [
    "# Stemmimng words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5e693",
   "metadata": {},
   "source": [
    "you have tokenized words and want to convert them into their root form\n",
    "\n",
    "use NLTK's PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b1d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "\n",
    "# create stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e93cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(i) for i in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df01ff",
   "metadata": {},
   "source": [
    "# Tagging Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4087a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tamilarasu16\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824821a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# create text data\n",
    "text_data = 'Chris loved outdoor running'\n",
    "\n",
    "# Use pre trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "\n",
    "# show parts of speech\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55000704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter words\n",
    "[word for word, tag in text_tagged if tag in ['NN', 'NNS', 'NNP', 'NNPS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c315f",
   "metadata": {},
   "source": [
    "A more realistic situation would be that we have data where every observation contains a tweet and we want to convert those sentences into features for indivudial parts of speech(e.g. a feature with 1 if a proper noun is present, and 0 otherwise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa065f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text\n",
    "tweets = ['I am eating a burrito for breakfast',\n",
    "         'Political science is an amaxing field',\n",
    "         'San Fransisco is an awesome city']\n",
    "\n",
    "# create list\n",
    "tagged_tweets = []\n",
    "\n",
    "# tag each word and each tweet\n",
    "for i in tweets:\n",
    "    tweet_tag = nltk.pos_tag(word_tokenize(i))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90888e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PRP', 'VBP', 'VBG', 'DT', 'NN', 'IN', 'NN'],\n",
       " ['JJ', 'NN', 'VBZ', 'DT', 'JJ', 'NN'],\n",
       " ['NNP', 'NNP', 'VBZ', 'DT', 'JJ', 'NN']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3afe679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use one hot encoding to convert the tags into features\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "one_hot_multi.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9866e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show feature names\n",
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bdb572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Tamilarasu16\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9902e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "# get some text from the brown corpus, broken into sentences\n",
    "sentences = brown.tagged_sents(categories='news')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "065e7ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamilarasu16\\AppData\\Local\\Temp\\ipykernel_9064\\477503844.py:11: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  trigram.evaluate(test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8174734002697437"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into 4000 sentences for training and 623 for testing\n",
    "train = sentences[:4000]\n",
    "test = sentences[4000:]\n",
    "\n",
    "# create backoff tagger\n",
    "unigram = UnigramTagger(train)\n",
    "bigram = BigramTagger(train, backoff=unigram)\n",
    "trigram = TrigramTagger(train, backoff=bigram)\n",
    "\n",
    "# show acccuracy\n",
    "trigram.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b66816",
   "metadata": {},
   "source": [
    "# Encoding text as a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6824b225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create text\n",
    "text_data = np.array(['I Love Brazil. Brazil',\n",
    "                     'Sweden is best',\n",
    "                     'Germany beats both'])\n",
    "\n",
    "# create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# show feature matrix\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff033735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3f0f2",
   "metadata": {},
   "source": [
    "We can use the vocabulary_method to view the word associated with each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3196e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show feature names\n",
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb74561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazil': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix with arguments\n",
    "count_2gram = CountVectorizer(ngram_range=(1,2),\n",
    "                             stop_words='english',\n",
    "                             vocabulary=['brazil'])\n",
    "bag = count_2gram.fit_transform(text_data)\n",
    "\n",
    "# view feature matrix\n",
    "bag.toarray()\n",
    "\n",
    "# view the 1 gramand 2 gram\n",
    "count_2gram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc579",
   "metadata": {},
   "source": [
    "# Generate the N-grams for the given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4784a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram: ['A', 'Class', 'is', 'a', 'blueprint', 'for', 'the', 'object', '.']\n",
      "2-gram: ['A Class', 'Class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object', 'object .']\n",
      "3-gram: ['A Class is', 'Class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object', 'the object .']\n",
      "4-gram: ['A Class is a', 'Class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object', 'for the object .']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# function to generate n grams from sentences\n",
    "\n",
    "def extract_n_grams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "data = 'A Class is a blueprint for the object.'\n",
    "\n",
    "print('1-gram:', extract_n_grams(data, 1))\n",
    "print('2-gram:', extract_n_grams(data, 2))\n",
    "print('3-gram:', extract_n_grams(data, 3))\n",
    "print('4-gram:', extract_n_grams(data, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1466b08",
   "metadata": {},
   "source": [
    "# Weighting word Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50c4e9",
   "metadata": {},
   "source": [
    "You want a bag of words, but with words weighted by their importance to an observation.\n",
    "\n",
    "Compare the frequency of the word in a document(a tweet, movie review, speech transcript,etc.) with the frequency of the word in all other documents using term frequency-inverse document frequency (tf-idf) scikit-learn makes this easy with TfidVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0431ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create text\n",
    "text_data = np.array(['I Love Brazil. Brazil',\n",
    "                     'Sweden is best',\n",
    "                     'Germany beats both'])\n",
    "\n",
    "# create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "# show tf-idf feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb7a7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f6b31",
   "metadata": {},
   "source": [
    "Vocabulary_shows us the word of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2a30d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show feature names\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b5d378",
   "metadata": {},
   "source": [
    "# Handling Dates and Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0337cf",
   "metadata": {},
   "source": [
    "# Converting Strings to Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234ac65",
   "metadata": {},
   "source": [
    "Given a vector of strings representing dates and times, you want to transform them into time series data\n",
    "\n",
    "Use pandas to_dateframe with the format of the date and/or time specified in the format parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81f68464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# create strings\n",
    "date_strings = np.array(['03-04-2005 11:35 PM',\n",
    "                        '23-05-2010 12:01 AM',\n",
    "                        '04-09-2009 09:09 PM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dd69451",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '03-04-2005 11:35 PM' does not match format '%d-%m-%y %I:%M %p' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert to datetimes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m [pd\u001b[38;5;241m.\u001b[39mto_datetime(date, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mI:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_strings]\n",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert to datetimes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m [\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mI:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_strings]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1102\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1104\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:430\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_to_datetime_with_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:538\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[38;5;241m=\u001b[39mutc, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fallback\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:473\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    470\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutOfBoundsDatetime:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:150\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '03-04-2005 11:35 PM' does not match format '%d-%m-%y %I:%M %p' (match)"
     ]
    }
   ],
   "source": [
    "# convert to datetimes\n",
    "[pd.to_datetime(date, format='%d-%m-%y %I:%M %p') for date in date_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cdfc8",
   "metadata": {},
   "source": [
    "We might also want to add an argument to the errors parameters to handle problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42b2b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NaT, NaT, NaT]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to datetimes\n",
    "[pd.to_datetime(date, format='%d-%m-%y %I:%M:%p', errors='coerce')\n",
    "for date in date_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49361d14",
   "metadata": {},
   "source": [
    "# Handling Time Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4520d9f2",
   "metadata": {},
   "source": [
    "you have time series data and want to add or change time zone information.\n",
    "\n",
    "If not specified, pandas objects have no time zone. However, we can add a time zone using tz during creation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb071102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 06:00:00+0100', tz='Europe/London')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# create datetime\n",
    "pd.Timestamp('2017-05-01 06:00:00', tz='Europe/London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adc1a3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 06:00:00+0100', tz='Europe/London')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create datetime\n",
    "date=pd.Timestamp('2017-05-01 06:00:00')\n",
    "\n",
    "# set time zone\n",
    "date_in_london = date.tz_localize('Europe/London')\n",
    "\n",
    "# show datetime\n",
    "date_in_london"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeba3f1",
   "metadata": {},
   "source": [
    "We can also convert to a different time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1424ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 05:00:00+0000', tz='Africa/Abidjan')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change time zone\n",
    "date_in_london.tz_convert('Africa/Abidjan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066ec36",
   "metadata": {},
   "source": [
    "Finally, pandas'Series objects can apply tz_localize and tz_convert to every element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2880b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three dates\n",
    "dates = pd.Series(pd.date_range('2/2/2002', periods=3, freq='M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "559ac5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-02-28\n",
       "1   2002-03-31\n",
       "2   2002-04-30\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d16886fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-02-28 00:00:00+00:00\n",
       "1   2002-03-31 00:00:00+00:00\n",
       "2   2002-04-30 00:00:00+00:00\n",
       "dtype: datetime64[ns, Africa/Abidjan]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set time zone\n",
    "dates.dt.tz_localize('Africa/Abidjan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51f8de",
   "metadata": {},
   "source": [
    "Pandas support two sets of strings representing timezones, however I suggest using pytz library's string. We can see all the strings used to represent time zones by importing all_timezones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bd84504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa/Abidjan',\n",
       " 'Africa/Accra',\n",
       " 'Africa/Addis_Ababa',\n",
       " 'Africa/Algiers',\n",
       " 'Africa/Asmara',\n",
       " 'Africa/Asmera',\n",
       " 'Africa/Bamako',\n",
       " 'Africa/Bangui',\n",
       " 'Africa/Banjul',\n",
       " 'Africa/Bissau',\n",
       " 'Africa/Blantyre',\n",
       " 'Africa/Brazzaville',\n",
       " 'Africa/Bujumbura',\n",
       " 'Africa/Cairo',\n",
       " 'Africa/Casablanca',\n",
       " 'Africa/Ceuta',\n",
       " 'Africa/Conakry',\n",
       " 'Africa/Dakar',\n",
       " 'Africa/Dar_es_Salaam',\n",
       " 'Africa/Djibouti',\n",
       " 'Africa/Douala',\n",
       " 'Africa/El_Aaiun',\n",
       " 'Africa/Freetown',\n",
       " 'Africa/Gaborone',\n",
       " 'Africa/Harare',\n",
       " 'Africa/Johannesburg',\n",
       " 'Africa/Juba',\n",
       " 'Africa/Kampala',\n",
       " 'Africa/Khartoum',\n",
       " 'Africa/Kigali',\n",
       " 'Africa/Kinshasa',\n",
       " 'Africa/Lagos',\n",
       " 'Africa/Libreville',\n",
       " 'Africa/Lome',\n",
       " 'Africa/Luanda',\n",
       " 'Africa/Lubumbashi',\n",
       " 'Africa/Lusaka',\n",
       " 'Africa/Malabo',\n",
       " 'Africa/Maputo',\n",
       " 'Africa/Maseru',\n",
       " 'Africa/Mbabane',\n",
       " 'Africa/Mogadishu',\n",
       " 'Africa/Monrovia',\n",
       " 'Africa/Nairobi',\n",
       " 'Africa/Ndjamena',\n",
       " 'Africa/Niamey',\n",
       " 'Africa/Nouakchott',\n",
       " 'Africa/Ouagadougou',\n",
       " 'Africa/Porto-Novo',\n",
       " 'Africa/Sao_Tome',\n",
       " 'Africa/Timbuktu',\n",
       " 'Africa/Tripoli',\n",
       " 'Africa/Tunis',\n",
       " 'Africa/Windhoek',\n",
       " 'America/Adak',\n",
       " 'America/Anchorage',\n",
       " 'America/Anguilla',\n",
       " 'America/Antigua',\n",
       " 'America/Araguaina',\n",
       " 'America/Argentina/Buenos_Aires',\n",
       " 'America/Argentina/Catamarca',\n",
       " 'America/Argentina/ComodRivadavia',\n",
       " 'America/Argentina/Cordoba',\n",
       " 'America/Argentina/Jujuy',\n",
       " 'America/Argentina/La_Rioja',\n",
       " 'America/Argentina/Mendoza',\n",
       " 'America/Argentina/Rio_Gallegos',\n",
       " 'America/Argentina/Salta',\n",
       " 'America/Argentina/San_Juan',\n",
       " 'America/Argentina/San_Luis',\n",
       " 'America/Argentina/Tucuman',\n",
       " 'America/Argentina/Ushuaia',\n",
       " 'America/Aruba',\n",
       " 'America/Asuncion',\n",
       " 'America/Atikokan',\n",
       " 'America/Atka',\n",
       " 'America/Bahia',\n",
       " 'America/Bahia_Banderas',\n",
       " 'America/Barbados',\n",
       " 'America/Belem',\n",
       " 'America/Belize',\n",
       " 'America/Blanc-Sablon',\n",
       " 'America/Boa_Vista',\n",
       " 'America/Bogota',\n",
       " 'America/Boise',\n",
       " 'America/Buenos_Aires',\n",
       " 'America/Cambridge_Bay',\n",
       " 'America/Campo_Grande',\n",
       " 'America/Cancun',\n",
       " 'America/Caracas',\n",
       " 'America/Catamarca',\n",
       " 'America/Cayenne',\n",
       " 'America/Cayman',\n",
       " 'America/Chicago',\n",
       " 'America/Chihuahua',\n",
       " 'America/Coral_Harbour',\n",
       " 'America/Cordoba',\n",
       " 'America/Costa_Rica',\n",
       " 'America/Creston',\n",
       " 'America/Cuiaba',\n",
       " 'America/Curacao',\n",
       " 'America/Danmarkshavn',\n",
       " 'America/Dawson',\n",
       " 'America/Dawson_Creek',\n",
       " 'America/Denver',\n",
       " 'America/Detroit',\n",
       " 'America/Dominica',\n",
       " 'America/Edmonton',\n",
       " 'America/Eirunepe',\n",
       " 'America/El_Salvador',\n",
       " 'America/Ensenada',\n",
       " 'America/Fort_Nelson',\n",
       " 'America/Fort_Wayne',\n",
       " 'America/Fortaleza',\n",
       " 'America/Glace_Bay',\n",
       " 'America/Godthab',\n",
       " 'America/Goose_Bay',\n",
       " 'America/Grand_Turk',\n",
       " 'America/Grenada',\n",
       " 'America/Guadeloupe',\n",
       " 'America/Guatemala',\n",
       " 'America/Guayaquil',\n",
       " 'America/Guyana',\n",
       " 'America/Halifax',\n",
       " 'America/Havana',\n",
       " 'America/Hermosillo',\n",
       " 'America/Indiana/Indianapolis',\n",
       " 'America/Indiana/Knox',\n",
       " 'America/Indiana/Marengo',\n",
       " 'America/Indiana/Petersburg',\n",
       " 'America/Indiana/Tell_City',\n",
       " 'America/Indiana/Vevay',\n",
       " 'America/Indiana/Vincennes',\n",
       " 'America/Indiana/Winamac',\n",
       " 'America/Indianapolis',\n",
       " 'America/Inuvik',\n",
       " 'America/Iqaluit',\n",
       " 'America/Jamaica',\n",
       " 'America/Jujuy',\n",
       " 'America/Juneau',\n",
       " 'America/Kentucky/Louisville',\n",
       " 'America/Kentucky/Monticello',\n",
       " 'America/Knox_IN',\n",
       " 'America/Kralendijk',\n",
       " 'America/La_Paz',\n",
       " 'America/Lima',\n",
       " 'America/Los_Angeles',\n",
       " 'America/Louisville',\n",
       " 'America/Lower_Princes',\n",
       " 'America/Maceio',\n",
       " 'America/Managua',\n",
       " 'America/Manaus',\n",
       " 'America/Marigot',\n",
       " 'America/Martinique',\n",
       " 'America/Matamoros',\n",
       " 'America/Mazatlan',\n",
       " 'America/Mendoza',\n",
       " 'America/Menominee',\n",
       " 'America/Merida',\n",
       " 'America/Metlakatla',\n",
       " 'America/Mexico_City',\n",
       " 'America/Miquelon',\n",
       " 'America/Moncton',\n",
       " 'America/Monterrey',\n",
       " 'America/Montevideo',\n",
       " 'America/Montreal',\n",
       " 'America/Montserrat',\n",
       " 'America/Nassau',\n",
       " 'America/New_York',\n",
       " 'America/Nipigon',\n",
       " 'America/Nome',\n",
       " 'America/Noronha',\n",
       " 'America/North_Dakota/Beulah',\n",
       " 'America/North_Dakota/Center',\n",
       " 'America/North_Dakota/New_Salem',\n",
       " 'America/Nuuk',\n",
       " 'America/Ojinaga',\n",
       " 'America/Panama',\n",
       " 'America/Pangnirtung',\n",
       " 'America/Paramaribo',\n",
       " 'America/Phoenix',\n",
       " 'America/Port-au-Prince',\n",
       " 'America/Port_of_Spain',\n",
       " 'America/Porto_Acre',\n",
       " 'America/Porto_Velho',\n",
       " 'America/Puerto_Rico',\n",
       " 'America/Punta_Arenas',\n",
       " 'America/Rainy_River',\n",
       " 'America/Rankin_Inlet',\n",
       " 'America/Recife',\n",
       " 'America/Regina',\n",
       " 'America/Resolute',\n",
       " 'America/Rio_Branco',\n",
       " 'America/Rosario',\n",
       " 'America/Santa_Isabel',\n",
       " 'America/Santarem',\n",
       " 'America/Santiago',\n",
       " 'America/Santo_Domingo',\n",
       " 'America/Sao_Paulo',\n",
       " 'America/Scoresbysund',\n",
       " 'America/Shiprock',\n",
       " 'America/Sitka',\n",
       " 'America/St_Barthelemy',\n",
       " 'America/St_Johns',\n",
       " 'America/St_Kitts',\n",
       " 'America/St_Lucia',\n",
       " 'America/St_Thomas',\n",
       " 'America/St_Vincent',\n",
       " 'America/Swift_Current',\n",
       " 'America/Tegucigalpa',\n",
       " 'America/Thule',\n",
       " 'America/Thunder_Bay',\n",
       " 'America/Tijuana',\n",
       " 'America/Toronto',\n",
       " 'America/Tortola',\n",
       " 'America/Vancouver',\n",
       " 'America/Virgin',\n",
       " 'America/Whitehorse',\n",
       " 'America/Winnipeg',\n",
       " 'America/Yakutat',\n",
       " 'America/Yellowknife',\n",
       " 'Antarctica/Casey',\n",
       " 'Antarctica/Davis',\n",
       " 'Antarctica/DumontDUrville',\n",
       " 'Antarctica/Macquarie',\n",
       " 'Antarctica/Mawson',\n",
       " 'Antarctica/McMurdo',\n",
       " 'Antarctica/Palmer',\n",
       " 'Antarctica/Rothera',\n",
       " 'Antarctica/South_Pole',\n",
       " 'Antarctica/Syowa',\n",
       " 'Antarctica/Troll',\n",
       " 'Antarctica/Vostok',\n",
       " 'Arctic/Longyearbyen',\n",
       " 'Asia/Aden',\n",
       " 'Asia/Almaty',\n",
       " 'Asia/Amman',\n",
       " 'Asia/Anadyr',\n",
       " 'Asia/Aqtau',\n",
       " 'Asia/Aqtobe',\n",
       " 'Asia/Ashgabat',\n",
       " 'Asia/Ashkhabad',\n",
       " 'Asia/Atyrau',\n",
       " 'Asia/Baghdad',\n",
       " 'Asia/Bahrain',\n",
       " 'Asia/Baku',\n",
       " 'Asia/Bangkok',\n",
       " 'Asia/Barnaul',\n",
       " 'Asia/Beirut',\n",
       " 'Asia/Bishkek',\n",
       " 'Asia/Brunei',\n",
       " 'Asia/Calcutta',\n",
       " 'Asia/Chita',\n",
       " 'Asia/Choibalsan',\n",
       " 'Asia/Chongqing',\n",
       " 'Asia/Chungking',\n",
       " 'Asia/Colombo',\n",
       " 'Asia/Dacca',\n",
       " 'Asia/Damascus',\n",
       " 'Asia/Dhaka',\n",
       " 'Asia/Dili',\n",
       " 'Asia/Dubai',\n",
       " 'Asia/Dushanbe',\n",
       " 'Asia/Famagusta',\n",
       " 'Asia/Gaza',\n",
       " 'Asia/Harbin',\n",
       " 'Asia/Hebron',\n",
       " 'Asia/Ho_Chi_Minh',\n",
       " 'Asia/Hong_Kong',\n",
       " 'Asia/Hovd',\n",
       " 'Asia/Irkutsk',\n",
       " 'Asia/Istanbul',\n",
       " 'Asia/Jakarta',\n",
       " 'Asia/Jayapura',\n",
       " 'Asia/Jerusalem',\n",
       " 'Asia/Kabul',\n",
       " 'Asia/Kamchatka',\n",
       " 'Asia/Karachi',\n",
       " 'Asia/Kashgar',\n",
       " 'Asia/Kathmandu',\n",
       " 'Asia/Katmandu',\n",
       " 'Asia/Khandyga',\n",
       " 'Asia/Kolkata',\n",
       " 'Asia/Krasnoyarsk',\n",
       " 'Asia/Kuala_Lumpur',\n",
       " 'Asia/Kuching',\n",
       " 'Asia/Kuwait',\n",
       " 'Asia/Macao',\n",
       " 'Asia/Macau',\n",
       " 'Asia/Magadan',\n",
       " 'Asia/Makassar',\n",
       " 'Asia/Manila',\n",
       " 'Asia/Muscat',\n",
       " 'Asia/Nicosia',\n",
       " 'Asia/Novokuznetsk',\n",
       " 'Asia/Novosibirsk',\n",
       " 'Asia/Omsk',\n",
       " 'Asia/Oral',\n",
       " 'Asia/Phnom_Penh',\n",
       " 'Asia/Pontianak',\n",
       " 'Asia/Pyongyang',\n",
       " 'Asia/Qatar',\n",
       " 'Asia/Qostanay',\n",
       " 'Asia/Qyzylorda',\n",
       " 'Asia/Rangoon',\n",
       " 'Asia/Riyadh',\n",
       " 'Asia/Saigon',\n",
       " 'Asia/Sakhalin',\n",
       " 'Asia/Samarkand',\n",
       " 'Asia/Seoul',\n",
       " 'Asia/Shanghai',\n",
       " 'Asia/Singapore',\n",
       " 'Asia/Srednekolymsk',\n",
       " 'Asia/Taipei',\n",
       " 'Asia/Tashkent',\n",
       " 'Asia/Tbilisi',\n",
       " 'Asia/Tehran',\n",
       " 'Asia/Tel_Aviv',\n",
       " 'Asia/Thimbu',\n",
       " 'Asia/Thimphu',\n",
       " 'Asia/Tokyo',\n",
       " 'Asia/Tomsk',\n",
       " 'Asia/Ujung_Pandang',\n",
       " 'Asia/Ulaanbaatar',\n",
       " 'Asia/Ulan_Bator',\n",
       " 'Asia/Urumqi',\n",
       " 'Asia/Ust-Nera',\n",
       " 'Asia/Vientiane',\n",
       " 'Asia/Vladivostok',\n",
       " 'Asia/Yakutsk',\n",
       " 'Asia/Yangon',\n",
       " 'Asia/Yekaterinburg',\n",
       " 'Asia/Yerevan',\n",
       " 'Atlantic/Azores',\n",
       " 'Atlantic/Bermuda',\n",
       " 'Atlantic/Canary',\n",
       " 'Atlantic/Cape_Verde',\n",
       " 'Atlantic/Faeroe',\n",
       " 'Atlantic/Faroe',\n",
       " 'Atlantic/Jan_Mayen',\n",
       " 'Atlantic/Madeira',\n",
       " 'Atlantic/Reykjavik',\n",
       " 'Atlantic/South_Georgia',\n",
       " 'Atlantic/St_Helena',\n",
       " 'Atlantic/Stanley',\n",
       " 'Australia/ACT',\n",
       " 'Australia/Adelaide',\n",
       " 'Australia/Brisbane',\n",
       " 'Australia/Broken_Hill',\n",
       " 'Australia/Canberra',\n",
       " 'Australia/Currie',\n",
       " 'Australia/Darwin',\n",
       " 'Australia/Eucla',\n",
       " 'Australia/Hobart',\n",
       " 'Australia/LHI',\n",
       " 'Australia/Lindeman',\n",
       " 'Australia/Lord_Howe',\n",
       " 'Australia/Melbourne',\n",
       " 'Australia/NSW',\n",
       " 'Australia/North',\n",
       " 'Australia/Perth',\n",
       " 'Australia/Queensland',\n",
       " 'Australia/South',\n",
       " 'Australia/Sydney',\n",
       " 'Australia/Tasmania',\n",
       " 'Australia/Victoria',\n",
       " 'Australia/West',\n",
       " 'Australia/Yancowinna',\n",
       " 'Brazil/Acre',\n",
       " 'Brazil/DeNoronha',\n",
       " 'Brazil/East',\n",
       " 'Brazil/West',\n",
       " 'CET',\n",
       " 'CST6CDT',\n",
       " 'Canada/Atlantic',\n",
       " 'Canada/Central',\n",
       " 'Canada/Eastern',\n",
       " 'Canada/Mountain',\n",
       " 'Canada/Newfoundland',\n",
       " 'Canada/Pacific',\n",
       " 'Canada/Saskatchewan',\n",
       " 'Canada/Yukon',\n",
       " 'Chile/Continental',\n",
       " 'Chile/EasterIsland',\n",
       " 'Cuba',\n",
       " 'EET',\n",
       " 'EST',\n",
       " 'EST5EDT',\n",
       " 'Egypt',\n",
       " 'Eire',\n",
       " 'Etc/GMT',\n",
       " 'Etc/GMT+0',\n",
       " 'Etc/GMT+1',\n",
       " 'Etc/GMT+10',\n",
       " 'Etc/GMT+11',\n",
       " 'Etc/GMT+12',\n",
       " 'Etc/GMT+2',\n",
       " 'Etc/GMT+3',\n",
       " 'Etc/GMT+4',\n",
       " 'Etc/GMT+5',\n",
       " 'Etc/GMT+6',\n",
       " 'Etc/GMT+7',\n",
       " 'Etc/GMT+8',\n",
       " 'Etc/GMT+9',\n",
       " 'Etc/GMT-0',\n",
       " 'Etc/GMT-1',\n",
       " 'Etc/GMT-10',\n",
       " 'Etc/GMT-11',\n",
       " 'Etc/GMT-12',\n",
       " 'Etc/GMT-13',\n",
       " 'Etc/GMT-14',\n",
       " 'Etc/GMT-2',\n",
       " 'Etc/GMT-3',\n",
       " 'Etc/GMT-4',\n",
       " 'Etc/GMT-5',\n",
       " 'Etc/GMT-6',\n",
       " 'Etc/GMT-7',\n",
       " 'Etc/GMT-8',\n",
       " 'Etc/GMT-9',\n",
       " 'Etc/GMT0',\n",
       " 'Etc/Greenwich',\n",
       " 'Etc/UCT',\n",
       " 'Etc/UTC',\n",
       " 'Etc/Universal',\n",
       " 'Etc/Zulu',\n",
       " 'Europe/Amsterdam',\n",
       " 'Europe/Andorra',\n",
       " 'Europe/Astrakhan',\n",
       " 'Europe/Athens',\n",
       " 'Europe/Belfast',\n",
       " 'Europe/Belgrade',\n",
       " 'Europe/Berlin',\n",
       " 'Europe/Bratislava',\n",
       " 'Europe/Brussels',\n",
       " 'Europe/Bucharest',\n",
       " 'Europe/Budapest',\n",
       " 'Europe/Busingen',\n",
       " 'Europe/Chisinau',\n",
       " 'Europe/Copenhagen',\n",
       " 'Europe/Dublin',\n",
       " 'Europe/Gibraltar',\n",
       " 'Europe/Guernsey',\n",
       " 'Europe/Helsinki',\n",
       " 'Europe/Isle_of_Man',\n",
       " 'Europe/Istanbul',\n",
       " 'Europe/Jersey',\n",
       " 'Europe/Kaliningrad',\n",
       " 'Europe/Kiev',\n",
       " 'Europe/Kirov',\n",
       " 'Europe/Kyiv',\n",
       " 'Europe/Lisbon',\n",
       " 'Europe/Ljubljana',\n",
       " 'Europe/London',\n",
       " 'Europe/Luxembourg',\n",
       " 'Europe/Madrid',\n",
       " 'Europe/Malta',\n",
       " 'Europe/Mariehamn',\n",
       " 'Europe/Minsk',\n",
       " 'Europe/Monaco',\n",
       " 'Europe/Moscow',\n",
       " 'Europe/Nicosia',\n",
       " 'Europe/Oslo',\n",
       " 'Europe/Paris',\n",
       " 'Europe/Podgorica',\n",
       " 'Europe/Prague',\n",
       " 'Europe/Riga',\n",
       " 'Europe/Rome',\n",
       " 'Europe/Samara',\n",
       " 'Europe/San_Marino',\n",
       " 'Europe/Sarajevo',\n",
       " 'Europe/Saratov',\n",
       " 'Europe/Simferopol',\n",
       " 'Europe/Skopje',\n",
       " 'Europe/Sofia',\n",
       " 'Europe/Stockholm',\n",
       " 'Europe/Tallinn',\n",
       " 'Europe/Tirane',\n",
       " 'Europe/Tiraspol',\n",
       " 'Europe/Ulyanovsk',\n",
       " 'Europe/Uzhgorod',\n",
       " 'Europe/Vaduz',\n",
       " 'Europe/Vatican',\n",
       " 'Europe/Vienna',\n",
       " 'Europe/Vilnius',\n",
       " 'Europe/Volgograd',\n",
       " 'Europe/Warsaw',\n",
       " 'Europe/Zagreb',\n",
       " 'Europe/Zaporozhye',\n",
       " 'Europe/Zurich',\n",
       " 'GB',\n",
       " 'GB-Eire',\n",
       " 'GMT',\n",
       " 'GMT+0',\n",
       " 'GMT-0',\n",
       " 'GMT0',\n",
       " 'Greenwich',\n",
       " 'HST',\n",
       " 'Hongkong',\n",
       " 'Iceland',\n",
       " 'Indian/Antananarivo',\n",
       " 'Indian/Chagos',\n",
       " 'Indian/Christmas',\n",
       " 'Indian/Cocos',\n",
       " 'Indian/Comoro',\n",
       " 'Indian/Kerguelen',\n",
       " 'Indian/Mahe',\n",
       " 'Indian/Maldives',\n",
       " 'Indian/Mauritius',\n",
       " 'Indian/Mayotte',\n",
       " 'Indian/Reunion',\n",
       " 'Iran',\n",
       " 'Israel',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Kwajalein',\n",
       " 'Libya',\n",
       " 'MET',\n",
       " 'MST',\n",
       " 'MST7MDT',\n",
       " 'Mexico/BajaNorte',\n",
       " 'Mexico/BajaSur',\n",
       " 'Mexico/General',\n",
       " 'NZ',\n",
       " 'NZ-CHAT',\n",
       " 'Navajo',\n",
       " 'PRC',\n",
       " 'PST8PDT',\n",
       " 'Pacific/Apia',\n",
       " 'Pacific/Auckland',\n",
       " 'Pacific/Bougainville',\n",
       " 'Pacific/Chatham',\n",
       " 'Pacific/Chuuk',\n",
       " 'Pacific/Easter',\n",
       " 'Pacific/Efate',\n",
       " 'Pacific/Enderbury',\n",
       " 'Pacific/Fakaofo',\n",
       " 'Pacific/Fiji',\n",
       " 'Pacific/Funafuti',\n",
       " 'Pacific/Galapagos',\n",
       " 'Pacific/Gambier',\n",
       " 'Pacific/Guadalcanal',\n",
       " 'Pacific/Guam',\n",
       " 'Pacific/Honolulu',\n",
       " 'Pacific/Johnston',\n",
       " 'Pacific/Kanton',\n",
       " 'Pacific/Kiritimati',\n",
       " 'Pacific/Kosrae',\n",
       " 'Pacific/Kwajalein',\n",
       " 'Pacific/Majuro',\n",
       " 'Pacific/Marquesas',\n",
       " 'Pacific/Midway',\n",
       " 'Pacific/Nauru',\n",
       " 'Pacific/Niue',\n",
       " 'Pacific/Norfolk',\n",
       " 'Pacific/Noumea',\n",
       " 'Pacific/Pago_Pago',\n",
       " 'Pacific/Palau',\n",
       " 'Pacific/Pitcairn',\n",
       " 'Pacific/Pohnpei',\n",
       " 'Pacific/Ponape',\n",
       " 'Pacific/Port_Moresby',\n",
       " 'Pacific/Rarotonga',\n",
       " 'Pacific/Saipan',\n",
       " 'Pacific/Samoa',\n",
       " 'Pacific/Tahiti',\n",
       " 'Pacific/Tarawa',\n",
       " 'Pacific/Tongatapu',\n",
       " 'Pacific/Truk',\n",
       " 'Pacific/Wake',\n",
       " 'Pacific/Wallis',\n",
       " 'Pacific/Yap',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'ROC',\n",
       " 'ROK',\n",
       " 'Singapore',\n",
       " 'Turkey',\n",
       " 'UCT',\n",
       " 'US/Alaska',\n",
       " 'US/Aleutian',\n",
       " 'US/Arizona',\n",
       " 'US/Central',\n",
       " 'US/East-Indiana',\n",
       " 'US/Eastern',\n",
       " 'US/Hawaii',\n",
       " 'US/Indiana-Starke',\n",
       " 'US/Michigan',\n",
       " 'US/Mountain',\n",
       " 'US/Pacific',\n",
       " 'US/Samoa',\n",
       " 'UTC',\n",
       " 'Universal',\n",
       " 'W-SU',\n",
       " 'WET',\n",
       " 'Zulu']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from pytz import all_timezones\n",
    "\n",
    "# see time zones\n",
    "all_timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e86a8b",
   "metadata": {},
   "source": [
    "# Selecting Dates and Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2854f08",
   "metadata": {},
   "source": [
    "You have a vector of dates and you want to select one or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59768dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2012-05-29 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2012-05-29 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2012-05-29 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2012-05-29 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2012-05-29 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date\n",
       "0     2001-01-01 00:00:00\n",
       "1     2001-01-01 01:00:00\n",
       "2     2001-01-01 02:00:00\n",
       "3     2001-01-01 03:00:00\n",
       "4     2001-01-01 04:00:00\n",
       "...                   ...\n",
       "99995 2012-05-29 11:00:00\n",
       "99996 2012-05-29 12:00:00\n",
       "99997 2012-05-29 13:00:00\n",
       "99998 2012-05-29 14:00:00\n",
       "99999 2012-05-29 15:00:00\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# Create datetimes\n",
    "dataframe['date'] = pd.date_range('1/1/2001', periods = 100000, freq = 'H')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27aee088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2002-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2002-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2002-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date\n",
       "8762 2002-01-01 02:00:00\n",
       "8763 2002-01-01 03:00:00\n",
       "8764 2002-01-01 04:00:00"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select observations between two datetimes\n",
    "dataframe[(dataframe['date'] > '2002-1-1 01:00:00') & (dataframe['date'] <= '2002-1-1-04:00:00')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a8911",
   "metadata": {},
   "source": [
    "Alternatively we can set the date column as the Dataframe's index and then slice using loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b9d86eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01 00:00:00</th>\n",
       "      <td>2001-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 01:00:00</th>\n",
       "      <td>2001-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 02:00:00</th>\n",
       "      <td>2001-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 03:00:00</th>\n",
       "      <td>2001-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 04:00:00</th>\n",
       "      <td>2001-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29 11:00:00</th>\n",
       "      <td>2012-05-29 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29 12:00:00</th>\n",
       "      <td>2012-05-29 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29 13:00:00</th>\n",
       "      <td>2012-05-29 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29 14:00:00</th>\n",
       "      <td>2012-05-29 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29 15:00:00</th>\n",
       "      <td>2012-05-29 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   date\n",
       "date                                   \n",
       "2001-01-01 00:00:00 2001-01-01 00:00:00\n",
       "2001-01-01 01:00:00 2001-01-01 01:00:00\n",
       "2001-01-01 02:00:00 2001-01-01 02:00:00\n",
       "2001-01-01 03:00:00 2001-01-01 03:00:00\n",
       "2001-01-01 04:00:00 2001-01-01 04:00:00\n",
       "...                                 ...\n",
       "2012-05-29 11:00:00 2012-05-29 11:00:00\n",
       "2012-05-29 12:00:00 2012-05-29 12:00:00\n",
       "2012-05-29 13:00:00 2012-05-29 13:00:00\n",
       "2012-05-29 14:00:00 2012-05-29 14:00:00\n",
       "2012-05-29 15:00:00 2012-05-29 15:00:00\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index\n",
    "dataframe = dataframe.set_index(dataframe['date'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f64ba8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01 01:00:00</th>\n",
       "      <td>2002-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 02:00:00</th>\n",
       "      <td>2002-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 03:00:00</th>\n",
       "      <td>2002-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01 04:00:00</th>\n",
       "      <td>2002-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   date\n",
       "date                                   \n",
       "2002-01-01 01:00:00 2002-01-01 01:00:00\n",
       "2002-01-01 02:00:00 2002-01-01 02:00:00\n",
       "2002-01-01 03:00:00 2002-01-01 03:00:00\n",
       "2002-01-01 04:00:00 2002-01-01 04:00:00"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select observations between two datetimes\n",
    "dataframe.loc['2002-1-1 01:00:00':'2002-1-1 04:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a828bd",
   "metadata": {},
   "source": [
    "# Breaking Up date data into multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56e6bc",
   "metadata": {},
   "source": [
    "You have a column of dates and times and you want to create features for year, month,day and minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d235c6d",
   "metadata": {},
   "source": [
    "Use Pandas Series.dt's time properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c9ab2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2003-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2003-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2003-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2003-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2003-11-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates\n",
       "0   2001-01-07\n",
       "1   2001-01-14\n",
       "2   2001-01-21\n",
       "3   2001-01-28\n",
       "4   2001-02-04\n",
       "..         ...\n",
       "145 2003-10-19\n",
       "146 2003-10-26\n",
       "147 2003-11-02\n",
       "148 2003-11-09\n",
       "149 2003-11-16\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# create five dates\n",
    "dataframe['dates'] = pd.date_range('1/1/2001', periods=150, freq='W')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1777f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-07</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-14</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-21</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-28</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02-04</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2003-10-19</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2003-10-26</td>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2003-11-02</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2003-11-09</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2003-11-16</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  year  month  day  hour  minute\n",
       "0   2001-01-07  2001      1    7     0       0\n",
       "1   2001-01-14  2001      1   14     0       0\n",
       "2   2001-01-21  2001      1   21     0       0\n",
       "3   2001-01-28  2001      1   28     0       0\n",
       "4   2001-02-04  2001      2    4     0       0\n",
       "..         ...   ...    ...  ...   ...     ...\n",
       "145 2003-10-19  2003     10   19     0       0\n",
       "146 2003-10-26  2003     10   26     0       0\n",
       "147 2003-11-02  2003     11    2     0       0\n",
       "148 2003-11-09  2003     11    9     0       0\n",
       "149 2003-11-16  2003     11   16     0       0\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create features for year,month,dat,hour and minute\n",
    "dataframe['year'] = dataframe['dates'].dt.year\n",
    "dataframe['month'] = dataframe['dates'].dt.month\n",
    "dataframe['day'] = dataframe['dates'].dt.day\n",
    "dataframe['hour'] = dataframe['dates'].dt.hour\n",
    "dataframe['minute'] = dataframe['dates'].dt.minute\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579a1d7",
   "metadata": {},
   "source": [
    "# Calculating the difference between dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd222d08",
   "metadata": {},
   "source": [
    "You have two datetime features and want to calculate the time between them for each observation\n",
    "\n",
    "subtract the two data features using pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3177e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0 days\n",
       "1   2 days\n",
       "dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create data frame\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# create two datetime features\n",
    "dataframe['Arrived'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-04-2017')]\n",
    "dataframe['Left'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-06-2017')]\n",
    "\n",
    "# calculate duration between features\n",
    "dataframe['Left'] - dataframe['Arrived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fcd3b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrived</th>\n",
       "      <th>Left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arrived       Left\n",
       "0 2017-01-01 2017-01-01\n",
       "1 2017-01-04 2017-01-06"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e1e3a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate duration between features\n",
    "pd.Series(delta.days for delta in (dataframe['Left'] - dataframe['Arrived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a14847",
   "metadata": {},
   "source": [
    "# Encoding Days of the Week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90ce28",
   "metadata": {},
   "source": [
    "you have a vector of dates and want to know the day of the week for each date.\n",
    "use pandas Series.dt property weekday_name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a55bc79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatetimeProperties' object has no attribute 'weekday_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [77], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(pd\u001b[38;5;241m.\u001b[39mdate_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2/2/2002\u001b[39m\u001b[38;5;124m'\u001b[39m,periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# show days of the week\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mdates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweekday_name\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatetimeProperties' object has no attribute 'weekday_name'"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "#Create dates\n",
    "dates = pd.Series(pd.date_range('2/2/2002',periods=3, freq='M'))\n",
    "\n",
    "# show days of the week\n",
    "dates.dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36862aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-02-28\n",
       "1   2002-03-31\n",
       "2   2002-04-30\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5e57f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    6\n",
       "2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad67c9f",
   "metadata": {},
   "source": [
    "# Creating a lagged Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722c4ee",
   "metadata": {},
   "source": [
    "you want to create a feature that is lagged n time periods\n",
    "use pandas's shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f724fc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>previous_days_stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dates  stock_price  previous_days_stock_price\n",
       "0 2001-01-01          1.1                        NaN\n",
       "1 2001-01-02          2.2                        1.1\n",
       "2 2001-01-03          3.3                        2.2\n",
       "3 2001-01-04          4.4                        3.3\n",
       "4 2001-01-05          5.5                        4.4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# Create data\n",
    "dataframe['dates'] = pd.date_range('1/1/2001', periods=5, freq='D')\n",
    "dataframe['stock_price'] = [1.1,2.2,3.3,4.4,5.5]\n",
    "\n",
    "# lagged values by one row\n",
    "dataframe['previous_days_stock_price'] = dataframe['stock_price'].shift(1)\n",
    "\n",
    "# show dataframe\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00b4a3",
   "metadata": {},
   "source": [
    "# Using Rolling Time Windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d09664",
   "metadata": {},
   "outputs": [],
   "source": [
    "Given time series data, you want to calculate some statistic fro a rolling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4da8efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library \n",
    "import pandas as pd\n",
    "\n",
    "# create datetimes\n",
    "time_index = pd.date_range('01/01/2010', periods=5, freq='M')\n",
    "\n",
    "# create data frame, set index\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "\n",
    "# create feature\n",
    "dataframe['Stock_price'] = [1,2,3,4,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e2ad177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Stock_price\n",
       "2010-01-31            1\n",
       "2010-02-28            2\n",
       "2010-03-31            3\n",
       "2010-04-30            4\n",
       "2010-05-31            5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cbb88a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Stock_price\n",
       "2010-01-31          NaN\n",
       "2010-02-28          1.5\n",
       "2010-03-31          2.5\n",
       "2010-04-30          3.5\n",
       "2010-05-31          4.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate rolling mean\n",
    "dataframe.rolling(window=2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e47af18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Stock_price\n",
       "2010-01-31          NaN\n",
       "2010-02-28          NaN\n",
       "2010-03-31          NaN\n",
       "2010-04-30          NaN\n",
       "2010-05-31          NaN"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate rolling mean\n",
    "dataframe.rolling(window=6).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c9b61",
   "metadata": {},
   "source": [
    "# handling missing data in time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "you can interpolation function to solve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0c7b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#create date\n",
    "time_index = pd.date_range('01/01/2010', periods=5, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f073fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-31', '2010-02-28', '2010-03-31', '2010-04-30',\n",
       "               '2010-05-31'],\n",
       "              dtype='datetime64[ns]', freq='M')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb1af771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe, set index\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "\n",
    "# create feature with a gap of missing values\n",
    "dataframe['Sales'] = [1.0, 2.0, np.nan, np.nan, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "793aefcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    NaN\n",
       "2010-04-30    NaN\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "035db4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    4.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate missing values\n",
    "dataframe.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a346c3d",
   "metadata": {},
   "source": [
    "Alternatively we can replace missing values with the last known value(i.e) forwardfilling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cdd1b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    2.0\n",
       "2010-04-30    2.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward filling\n",
    "dataframe.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec2bffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    5.0\n",
       "2010-04-30    5.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use backward filling\n",
    "\n",
    "dataframe.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97c72e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    4.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate misssing values\n",
    "dataframe.interpolate(methods = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a00441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    4.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate misssing values\n",
    "dataframe.interpolate(methods = 'pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82a78f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    NaN\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also give limit in interpolate\n",
    "\n",
    "dataframe.interpolate(limit=1, limit_direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c9c52f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    NaN\n",
       "2010-04-30    4.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also give limit in interpolate\n",
    "\n",
    "dataframe.interpolate(limit=1, limit_direction='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d7d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf771478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d66e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c0324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9570fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09ef9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
